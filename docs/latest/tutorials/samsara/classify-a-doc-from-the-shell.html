

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Text Classification Example</title>
  
  <meta name="author" content="Apache Mahout">

  <!-- Enable responsive viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Bootstrap styles -->
  <link href="/assets/themes/mahout3/css/bootstrap.min.css" rel="stylesheet">
  <!-- Optional theme -->
  <link href="/assets/themes/mahout3/css/bootstrap-theme.min.css" rel="stylesheet">
  <!-- Sticky Footer -->
  <link href="/assets/themes/mahout3/css/bs-sticky-footer.css" rel="stylesheet">

  <!-- Custom styles -->
  <link href="/assets/themes/mahout3/css/style.css" rel="stylesheet" type="text/css" media="all">

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
  <![endif]-->

  <!-- Fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->

  <!-- atom & rss feed -->
  <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
  <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
  </script>
  <script type="text/javascript">
    var mathjax = document.createElement('script');
    mathjax.type = 'text/javascript';
    mathjax.async = true;

    mathjax.src = ('https:' == document.location.protocol) ?
        'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML' :
        'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';

      var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(mathjax, s);
  </script>
</head>

<nav class="navbar navbar-default navbar-fixed-top">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">
        <img src="/assets/img/Mahout-logo-82x100.png" height="30" alt="I'm mahout">
      </a>
    </div>

    


<!-- Collect the nav links, forms, and other content for toggling -->
<div class="collapse navbar-collapse" id="main-navbar">
    <ul class="nav navbar-nav">

        <!-- Quick Start -->
        <li id="quickstart">
            <a href="/index.html" >Mahout Overview</a>
        </li>

        <li id="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Key Concepts<span class="caret"></span></a>
            <ul class="dropdown-menu">
                <li><a href="/index.html">Mahout Overview</a></li>
                <li><span><b>&nbsp;&nbsp;Scala DSL</b><span></li>
                <li><a href="/mahout-samsara/in-core-reference.html">In-core Reference</a></li>
                <li><a href="/mahout-samsara/out-of-core-reference.html">Out-of-core Reference</a></li>
                <li><a href="/mahout-samsara/faq.html">Samsara FAQ</a></li>
                <li role="separator" class="divider"></li>
                <li><span>&nbsp;&nbsp;<b>Bindings</b><span></li>
                <li><a href="/distributed/spark-bindings/">Spark Bindings</a></li>
                <li><a href="/distributed/flink-bindings.html">Flink Bindings</a></li>
                <li><a href="/distributed/flink-bindings.html">H20 Bindings</a></li>
                <!--<li role="separator" class="divider"></li>
                <li><span>&nbsp;&nbsp;<b>Native Solvers</b><span></li>
                <li><a href="/native-solvers/viennacl.html">ViennaCL</a></li>
                <li><a href="/native-solvers/viennacl-omp.html">ViennaCL-OMP</a></li>
                <li><a href="/native-solvers/cuda.html">CUDA</a></li>-->
            </ul>
        </li>

        <li id="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Tutorials<span class="caret"></span></a>
            <ul class="dropdown-menu">
                <li><span>&nbsp;&nbsp;<b>Reccomenders</b><span></li>
                <li><a href="/tutorials/cco-lastfm">CCO Example with Last.FM Data</a></li>
                <li><a href="/tutorials/intro-cooccurrence-spark">Introduction to Cooccurrence in Spark</a></li>
                <li role="separator" class="divider"></li>
                <li><span>&nbsp;&nbsp;<b>Mahout Samsara</b><span></li>
                <li><a href="/tutorials/samsara/play-with-shell.html">Playing with Samsara in Spark Shell</a></li>
                <li><a href="/tutorials/samsara/playing-with-samsara-flink-batch.html">Playing with Samsara in Flink Batch</a></li>
                <li><a href="/tutorials/samsara/classify-a-doc-from-the-shell.html">Text Classification (Shell)</a></li>
                <li><a href="/tutorials/samsara/spark-naive-bayes.html">Spark Naive Bayes</a></li>
                <li role="separator" class="divider"></li>
                <li><span>&nbsp;&nbsp;<b>Misc</b><span></li>
                <li><a href="/tutorials/misc/mahout-in-zeppelin">Mahout in Apache Zeppelin</a></li>
                <li><a href="/tutorials/misc/contributing-algos">How To Contribute a New Algorithm</a></li>
                <li><a href="/tutorials/misc/how-to-build-an-app.html">How To Build An App</a></li>
                <li role="separator" class="divider"></li>
                <li><span>&nbsp;&nbsp;<b>Deprecated</b><span></li>
                <li><a href="/tutorials/map-reduce">MapReduce</a></li>
            </ul>
        </li>


        <!-- Algorithms (Samsara / MR) -->
        <li id="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Algorithms<span class="caret"></span></a>
            <ul class="dropdown-menu">
                <li><a href="/algorithms/linear-algebra">Distributed Linear Algebra</a></li>
                <li><a href="/algorithms/preprocessors">Preprocessors</a></li>
                <li><a href="/algorithms/regression">Regression</a></li>
                <li><a href="/algorithms/reccomenders">Reccomenders</a></li>
                <li role="separator" class="divider"></li>
                <li><a href="/algorithms/map-reduce">MapReduce <i>(deprecated)</i></a></li>
            </ul>
                <!--<li><a href="/algorithms/reccomenders/recommender-overview.html">Reccomender Overview</a></li> Do we still need? seems like short version of next post-->
                <!--
                <li><a href="/algorithms/reccomenders/intro-cooccurrence-spark.html">Intro to Coocurrence With Spark</a></li>
                <li role="separator" class="divider"></li>
                <li><span>&nbsp;&nbsp;<a href="/algorithms/map-reduce"><b>MapReduce</b> (deprecated)</a><span></li>


             -->
        </li>

        <!-- Scala Docs -->
        <li id="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">API Docs<span class="caret"></span></a>
            <ul class="dropdown-menu">
                <li><a href="/0.13.0/api/index.html">0.13.0</a></li>
            </ul>
        </li>


    </ul>
    <form class="navbar-form navbar-left">
        <div class="form-group">
            <input type="text" class="form-control" placeholder="Search">
        </div>
        <button type="submit" class="btn btn-default">Submit</button>
    </form>
    <ul class="nav navbar-nav navbar-right">
        <li><a href="http://github.com/apache/mahout">Github</a></li>

        <!-- Apache -->
        <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Apache <span class="caret"></span></a>
            <ul class="dropdown-menu">
                <li><a href="http://www.apache.org/foundation/how-it-works.html">Apache Software Foundation</a></li>
                <li><a href="http://www.apache.org/licenses/">Apache License</a></li>
                <li><a href="http://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
                <li><a href="http://www.apache.org/foundation/thanks.html">Thanks</a></li>
            </ul>
        </li>

    </ul>
</div><!-- /.navbar-collapse -->

  </div><!-- /.container-fluid -->
</nav>

<body>

<div id="wrap">
  <body class="">

  <div class="container">
    


<div class="row">
    <div class="col-xs-3">
        <div id="TutorialMenu">
    <span><b>Tutorials</b></span>
    <div class="list-group panel">
        <a href="#linalg" class="list-group-item list-group-item-success" data-toggle="collapse" data-parent="#TutorialMenu"><b>Linear Algebra</b><i class="fa fa-caret-down"></i></a>
            <div class="collapse" id="linalg">
                <ul class="nav sidebar-nav">
                    <li><a href="/tutorials/eigenfaces">Eigenfaces Demo (Shell or Zeppelin)</a></li>
                </ul>
            </div>
        <a href="#reccomenders" class="list-group-item list-group-item-success" data-toggle="collapse" data-parent="#TutorialMenu"><b>Reccomenders</b><i class="fa fa-caret-down"></i></a>
            <div class="collapse" id="reccomenders">
                <ul class="nav sidebar-nav">
                    <li><a href="/tutorials/cco-lastfm">CCO Example with Last.FM Data</a></li>
                    <li><a href="/tutorials/intro-cooccurrence-spark">Introduction to Cooccurrence in Spark</a></li>
                </ul>
            </div>
        <a href="#other" class="list-group-item list-group-item-success" data-toggle="collapse" data-parent="#TutorialMenu"><b>Other</b><i class="fa fa-caret-down"></i></a>
        <div class="collapse" id="other">
            <ul class="nav sidebar-nav">
                <li><a href="/tutorials/misc/mahout-in-zeppelin">Mahout in Apache Zeppelin</a></li>
                <li><a href="/tutorials/misc/contributing-algos">How To Contribute a New Algorithm</a></li>
                <li><a href="/tutorials/misc/how-to-build-an-app.html">How To Build An App</a></li>
            </ul>
        </div>
    </div>
    <span><b>Map Reduce Tutorials</b> (deprecated)</span>
    <div class="list-group panel">
        <a href="#classification" class="list-group-item list-group-item-success" data-toggle="collapse" data-parent="#MrTutorialMenu"><b>Classification</b><i class="fa fa-caret-down"></i></a>
        <div class="collapse" id="classification">
            <ul class="nav sidebar-nav">
                <li> <a href="/tutorials/map-reduce/classification/bankmarketing-example.html">Bank Marketing Example</a></li>
                <li> <a href="/tutorials/map-reduce/classification/breiman-example.html">Breiman Example</a></li>
                <li> <a href="/tutorials/map-reduce/classification/twenty-newsgroups.html">Twenty Newsgroups Example</a></li>
                <li> <a href="/tutorials/map-reduce/classification/wikipedia-classifier-example.html">Wikipedia Classifier Example</a></li>
                <li> <a href="/tutorials/map-reduce/classification/parallel-frequent-pattern-mining.html">Parallel Frequent Pattern Mining</a></li>
            </ul>
        </div>
        <a href="#clustering" class="list-group-item list-group-item-success" data-toggle="collapse" data-parent="#MrTutorialMenu"><b>Clustering</b><i class="fa fa-caret-down"></i></a>
        <div class="collapse" id="clustering">
            <ul class="nav sidebar-nav">
                <li> <a href="/tutorials/map-reduce/clustering/20newsgroups.html">Twenty Newsgroups Example</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/canopy-commandline.html">Canopy Clustering from the Commandline</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/clustering-of-synthetic-control-data.html">Clustering of Synthetic Control Data</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/clustering-seinfeld-episodes.html">Clustering of Seinfeld Episodes</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/clusteringyourdata.html">Clustering Your Data</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/fuzzy-k-means-commandline.html">Fuzzy K-Means from the Commandline</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/k-means-commandline.html">K-Means from the Commandline</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/lda-commandline.html">LDA from the Commandline</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/viewing-results.html">Viewing Results</a></li>
                <li> <a href="/tutorials/map-reduce/clustering/visualizing-sample-clusters.html">Visualizing Sample Clusters</a></li>
            </ul>
        </div>
        <a href="#misc" class="list-group-item list-group-item-success" data-toggle="collapse" data-parent="#MrTutorialMenu"><b>Miscelaneous</b><i class="fa fa-caret-down"></i></a>
        <div class="collapse" id="misc">
            <ul class="nav sidebar-nav">
                <li> <a href="/tutorials/map-reduce/misc/mr---map-reduce.html">MR Map-Reduce</a></li>
                <li> <a href="/tutorials/map-reduce/misc/parallel-frequent-pattern-mining.html">Parallel Frequent Pattern Mining</a></li>
                <li> <a href="/tutorials/map-reduce/misc/using-mahout-with-python-via-jpype.html">Using Mahout (Map Reduce) with Python via Jpype</a></li>
            </ul>
        </div>
    </div>
</div>

    </div>

    <div class="col-xs-8">
        <div class="page-header">
            <h1>Text Classification Example </h1>
        </div>
        <h1 id="building-a-text-classifier-in-mahouts-spark-shell">Building a text classifier in Mahout’s Spark Shell</h1>

<p>This tutorial will take you through the steps used to train a Multinomial Naive Bayes model and create a text classifier based on that model using the <code>mahout spark-shell</code>.</p>

<h2 id="prerequisites">Prerequisites</h2>
<p>This tutorial assumes that you have your Spark environment variables set for the <code>mahout spark-shell</code> see: <a href="http://mahout.apache.org/users/sparkbindings/play-with-shell.html">Playing with Mahout’s Shell</a>.  As well we assume that Mahout is running in cluster mode (i.e. with the <code>MAHOUT_LOCAL</code> environment variable <strong>unset</strong>) as we’ll be reading and writing to HDFS.</p>

<h2 id="downloading-and-vectorizing-the-wikipedia-dataset">Downloading and Vectorizing the Wikipedia dataset</h2>
<p><em>As of Mahout v. 0.10.0, we are still reliant on the MapReduce versions of <code>mahout seqwiki</code> and <code>mahout seq2sparse</code> to extract and vectorize our text.  A</em> <a href="https://issues.apache.org/jira/browse/MAHOUT-1663"><em>Spark implementation of seq2sparse</em></a> <em>is in the works for Mahout v. 0.11.</em> However, to download the Wikipedia dataset, extract the bodies of the documentation, label each document and vectorize the text into TF-IDF vectors, we can simpmly run the <a href="https://github.com/apache/mahout/blob/master/examples/bin/classify-wikipedia.sh">wikipedia-classifier.sh</a> example.</p>

<pre><code>Please select a number to choose the corresponding task to run
1. CBayes (may require increased heap space on yarn)
2. BinaryCBayes
3. clean -- cleans up the work area in /tmp/mahout-work-wiki
Enter your choice :
</code></pre>

<p>Enter (2). This will download a large recent XML dump of the Wikipedia database, into a <code>/tmp/mahout-work-wiki</code> directory, unzip it and  place it into HDFS.  It will run a <a href="http://mahout.apache.org/users/classification/wikipedia-classifier-example.html">MapReduce job to parse the wikipedia set</a>, extracting and labeling only pages with category tags for [United States] and [United Kingdom] (~11600 documents). It will then run <code>mahout seq2sparse</code> to convert the documents into TF-IDF vectors.  The script will also a build and test a <a href="http://mahout.apache.org/users/classification/bayesian.html">Naive Bayes model using MapReduce</a>.  When it is completed, you should see a confusion matrix on your screen.  For this tutorial, we will ignore the MapReduce model, and build a new model using Spark based on the vectorized text output by <code>seq2sparse</code>.</p>

<h2 id="getting-started">Getting Started</h2>

<p>Launch the <code>mahout spark-shell</code>.  There is an example script: <code>spark-document-classifier.mscala</code> (.mscala denotes a Mahout-Scala script which can be run similarly to an R script).   We will be walking through this script for this tutorial but if you wanted to simply run the script, you could just issue the command:</p>

<pre><code>mahout&gt; :load /path/to/mahout/examples/bin/spark-document-classifier.mscala
</code></pre>

<p>For now, lets take the script apart piece by piece.  You can cut and paste the following code blocks into the <code>mahout spark-shell</code>.</p>

<h2 id="imports">Imports</h2>

<p>Our Mahout Naive Bayes imports:</p>

<pre><code>import org.apache.mahout.classifier.naivebayes._
import org.apache.mahout.classifier.stats._
import org.apache.mahout.nlp.tfidf._
</code></pre>

<p>Hadoop imports needed to read our dictionary:</p>

<pre><code>import org.apache.hadoop.io.Text
import org.apache.hadoop.io.IntWritable
import org.apache.hadoop.io.LongWritable
</code></pre>

<h2 id="read-in-our-full-set-from-hdfs-as-vectorized-by-seq2sparse-in-classify-wikipediash">Read in our full set from HDFS as vectorized by seq2sparse in classify-wikipedia.sh</h2>

<pre><code>val pathToData = "/tmp/mahout-work-wiki/"
val fullData = drmDfsRead(pathToData + "wikipediaVecs/tfidf-vectors")
</code></pre>

<h2 id="extract-the-category-of-each-observation-and-aggregate-those-observations-by-category">Extract the category of each observation and aggregate those observations by category</h2>

<pre><code>val (labelIndex, aggregatedObservations) = SparkNaiveBayes.extractLabelsAndAggregateObservations(
                                                             fullData)
</code></pre>

<h2 id="build-a-muitinomial-naive-bayes-model-and-self-test-on-the-training-set">Build a Muitinomial Naive Bayes model and self test on the training set</h2>

<pre><code>val model = SparkNaiveBayes.train(aggregatedObservations, labelIndex, false)
val resAnalyzer = SparkNaiveBayes.test(model, fullData, false)
println(resAnalyzer)
</code></pre>

<p>printing the <code>ResultAnalyzer</code> will display the confusion matrix.</p>

<h2 id="read-in-the-dictionary-and-document-frequency-count-from-hdfs">Read in the dictionary and document frequency count from HDFS</h2>

<pre><code>val dictionary = sdc.sequenceFile(pathToData + "wikipediaVecs/dictionary.file-0",
                                  classOf[Text],
                                  classOf[IntWritable])
val documentFrequencyCount = sdc.sequenceFile(pathToData + "wikipediaVecs/df-count",
                                              classOf[IntWritable],
                                              classOf[LongWritable])

// setup the dictionary and document frequency count as maps
val dictionaryRDD = dictionary.map { 
                                case (wKey, wVal) =&gt; wKey.asInstanceOf[Text]
                                                         .toString() -&gt; wVal.get() 
                                   }
                                   
val documentFrequencyCountRDD = documentFrequencyCount.map {
                                        case (wKey, wVal) =&gt; wKey.asInstanceOf[IntWritable]
                                                                 .get() -&gt; wVal.get() 
                                                           }

val dictionaryMap = dictionaryRDD.collect.map(x =&gt; x._1.toString -&gt; x._2.toInt).toMap
val dfCountMap = documentFrequencyCountRDD.collect.map(x =&gt; x._1.toInt -&gt; x._2.toLong).toMap
</code></pre>

<h2 id="define-a-function-to-tokenize-and-vectorize-new-text-using-our-current-dictionary">Define a function to tokenize and vectorize new text using our current dictionary</h2>

<p>For this simple example, our function <code>vectorizeDocument(...)</code> will tokenize a new document into unigrams using native Java String methods and vectorize using our dictionary and document frequencies. You could also use a <a href="https://lucene.apache.org/core/">Lucene</a> analyzer for bigrams, trigrams, etc., and integrate Apache <a href="https://tika.apache.org/">Tika</a> to extract text from different document types (PDF, PPT, XLS, etc.).  Here, however we will keep it simple, stripping and tokenizing our text using regexs and native String methods.</p>

<pre><code>def vectorizeDocument(document: String,
                        dictionaryMap: Map[String,Int],
                        dfMap: Map[Int,Long]): Vector = {
    val wordCounts = document.replaceAll("[^\\p{L}\\p{Nd}]+", " ")
                                .toLowerCase
                                .split(" ")
                                .groupBy(identity)
                                .mapValues(_.length)         
    val vec = new RandomAccessSparseVector(dictionaryMap.size)
    val totalDFSize = dfMap(-1)
    val docSize = wordCounts.size
    for (word &lt;- wordCounts) {
        val term = word._1
        if (dictionaryMap.contains(term)) {
            val tfidf: TermWeight = new TFIDF()
            val termFreq = word._2
            val dictIndex = dictionaryMap(term)
            val docFreq = dfCountMap(dictIndex)
            val currentTfIdf = tfidf.calculate(termFreq,
                                               docFreq.toInt,
                                               docSize,
                                               totalDFSize.toInt)
            vec.setQuick(dictIndex, currentTfIdf)
        }
    }
    vec
}
</code></pre>

<h2 id="setup-our-classifier">Setup our classifier</h2>

<pre><code>val labelMap = model.labelIndex
val numLabels = model.numLabels
val reverseLabelMap = labelMap.map(x =&gt; x._2 -&gt; x._1)

// instantiate the correct type of classifier
val classifier = model.isComplementary match {
    case true =&gt; new ComplementaryNBClassifier(model)
    case _ =&gt; new StandardNBClassifier(model)
}
</code></pre>

<h2 id="define-an-argmax-function">Define an argmax function</h2>

<p>The label with the highest score wins the classification for a given document.</p>

<pre><code>def argmax(v: Vector): (Int, Double) = {
    var bestIdx: Int = Integer.MIN_VALUE
    var bestScore: Double = Integer.MIN_VALUE.asInstanceOf[Int].toDouble
    for(i &lt;- 0 until v.size) {
        if(v(i) &gt; bestScore){
            bestScore = v(i)
            bestIdx = i
        }
    }
    (bestIdx, bestScore)
}
</code></pre>

<h2 id="define-our-tf-idf-vector-classifier">Define our TF(-IDF) vector classifier</h2>

<pre><code>def classifyDocument(clvec: Vector) : String = {
    val cvec = classifier.classifyFull(clvec)
    val (bestIdx, bestScore) = argmax(cvec)
    reverseLabelMap(bestIdx)
}
</code></pre>

<h2 id="two-sample-news-articles-united-states-football-and-united-kingdom-football">Two sample news articles: United States Football and United Kingdom Football</h2>

<pre><code>// A random United States football article
// http://www.reuters.com/article/2015/01/28/us-nfl-superbowl-security-idUSKBN0L12JR20150128
val UStextToClassify = new String("(Reuters) - Super Bowl security officials acknowledge" +
    " the NFL championship game represents a high profile target on a world stage but are" +
    " unaware of any specific credible threats against Sunday's showcase. In advance of" +
    " one of the world's biggest single day sporting events, Homeland Security Secretary" +
    " Jeh Johnson was in Glendale on Wednesday to review security preparations and tour" +
    " University of Phoenix Stadium where the Seattle Seahawks and New England Patriots" +
    " will battle. Deadly shootings in Paris and arrest of suspects in Belgium, Greece and" +
    " Germany heightened fears of more attacks around the world and social media accounts" +
    " linked to Middle East militant groups have carried a number of threats to attack" +
    " high-profile U.S. events. There is no specific credible threat, said Johnson, who" + 
    " has appointed a federal coordination team to work with local, state and federal" +
    " agencies to ensure safety of fans, players and other workers associated with the" + 
    " Super Bowl. I'm confident we will have a safe and secure and successful event." +
    " Sunday's game has been given a Special Event Assessment Rating (SEAR) 1 rating, the" +
    " same as in previous years, except for the year after the Sept. 11, 2001 attacks, when" +
    " a higher level was declared. But security will be tight and visible around Super" +
    " Bowl-related events as well as during the game itself. All fans will pass through" +
    " metal detectors and pat downs. Over 4,000 private security personnel will be deployed" +
    " and the almost 3,000 member Phoenix police force will be on Super Bowl duty. Nuclear" +
    " device sniffing teams will be deployed and a network of Bio-Watch detectors will be" +
    " set up to provide a warning in the event of a biological attack. The Department of" +
    " Homeland Security (DHS) said in a press release it had held special cyber-security" +
    " and anti-sniper training sessions. A U.S. official said the Transportation Security" +
    " Administration, which is responsible for screening airline passengers, will add" +
    " screeners and checkpoint lanes at airports. Federal air marshals, behavior detection" +
    " officers and dog teams will help to secure transportation systems in the area. We" +
    " will be ramping it (security) up on Sunday, there is no doubt about that, said Federal"+
    " Coordinator Matthew Allen, the DHS point of contact for planning and support. I have" +
    " every confidence the public safety agencies that represented in the planning process" +
    " are going to have their best and brightest out there this weekend and we will have" +
    " a very safe Super Bowl.")

// A random United Kingdom football article
// http://www.reuters.com/article/2015/01/26/manchester-united-swissquote-idUSL6N0V52RZ20150126
val UKtextToClassify = new String("(Reuters) - Manchester United have signed a sponsorship" +
    " deal with online financial trading company Swissquote, expanding the commercial" +
    " partnerships that have helped to make the English club one of the richest teams in" +
    " world soccer. United did not give a value for the deal, the club's first in the sector," +
    " but said on Monday it was a multi-year agreement. The Premier League club, 20 times" +
    " English champions, claim to have 659 million followers around the globe, making the" +
    " United name attractive to major brands like Chevrolet cars and sportswear group Adidas." +
    " Swissquote said the global deal would allow it to use United's popularity in Asia to" +
    " help it meet its targets for expansion in China. Among benefits from the deal," +
    " Swissquote's clients will have a chance to meet United players and get behind the scenes" +
    " at the Old Trafford stadium. Swissquote is a Geneva-based online trading company that" +
    " allows retail investors to buy and sell foreign exchange, equities, bonds and other asset" +
    " classes. Like other retail FX brokers, Swissquote was left nursing losses on the Swiss" +
    " franc after Switzerland's central bank stunned markets this month by abandoning its cap" +
    " on the currency. The fallout from the abrupt move put rival and West Ham United shirt" +
    " sponsor Alpari UK into administration. Swissquote itself was forced to book a 25 million" +
    " Swiss francs ($28 million) provision for its clients who were left out of pocket" +
    " following the franc's surge. United's ability to grow revenues off the pitch has made" +
    " them the second richest club in the world behind Spain's Real Madrid, despite a" +
    " downturn in their playing fortunes. United Managing Director Richard Arnold said" +
    " there was still lots of scope for United to develop sponsorships in other areas of" +
    " business. The last quoted statistics that we had showed that of the top 25 sponsorship" +
    " categories, we were only active in 15 of those, Arnold told Reuters. I think there is a" +
    " huge potential still for the club, and the other thing we have seen is there is very" +
    " significant growth even within categories. United have endured a tricky transition" +
    " following the retirement of manager Alex Ferguson in 2013, finishing seventh in the" +
    " Premier League last season and missing out on a place in the lucrative Champions League." +
    " ($1 = 0.8910 Swiss francs) (Writing by Neil Maidment, additional reporting by Jemima" + 
    " Kelly; editing by Keith Weir)")
</code></pre>

<h2 id="vectorize-and-classify-our-documents">Vectorize and classify our documents</h2>

<pre><code>val usVec = vectorizeDocument(UStextToClassify, dictionaryMap, dfCountMap)
val ukVec = vectorizeDocument(UKtextToClassify, dictionaryMap, dfCountMap)

println("Classifying the news article about superbowl security (united states)")
classifyDocument(usVec)

println("Classifying the news article about Manchester United (united kingdom)")
classifyDocument(ukVec)
</code></pre>

<h2 id="tie-everything-together-in-a-new-method-to-classify-text">Tie everything together in a new method to classify text</h2>

<pre><code>def classifyText(txt: String): String = {
    val v = vectorizeDocument(txt, dictionaryMap, dfCountMap)
    classifyDocument(v)
}
</code></pre>

<h2 id="now-we-can-simply-call-our-classifytext-method-on-any-string">Now we can simply call our classifyText(…) method on any String</h2>

<pre><code>classifyText("Hello world from Queens")
classifyText("Hello world from London")
</code></pre>

<h2 id="model-persistance">Model persistance</h2>

<p>You can save the model to HDFS:</p>

<pre><code>model.dfsWrite("/path/to/model")
</code></pre>

<p>And retrieve it with:</p>

<pre><code>val model =  NBModel.dfsRead("/path/to/model")
</code></pre>

<p>The trained model can now be embedded in an external application.</p>

    </div>
</div>

  </div>


</div>

<div id="footer">
  <div class="container">
    <p>&copy; 2017 Apache Mahout
      with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
      and <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>
    </p>
  </div>
</div>







<!-- Latest compiled and minified JavaScript, requires jQuery 1.x (2.x not supported in IE8) -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="/assets/themes/mahout3/js/bootstrap.min.js"></script>
</body>
</html>

