<p>The <a href="http://zeppelin.apache.org">Apache Zeppelin</a> is an exciting notebooking tool, designed for working with Big Data
applications.  It comes with great integration for graphing in R and Python, supports multiple langauges in a single 
notebook (and facilitates sharing of variables between interpreters), and makes working with Spark and Flink in an interactive environment (either locally or in cluster mode) a 
breeze.  Of course, it does lots of other cool things too- but those are the features we’re going to take advantage of.</p>

<h3 id="step1-download-and-install-zeppelin">Step1: Download and Install Zeppelin</h3>

<p>Zeppelin binaries by default use Spark 2.1 / Scala 2.11, until Mahout puts out Spark 2.1/Scala 2.11 binaries you have
two options.</p>

<h4 id="option-1-build-mahout-for-spark-21scala-211">Option 1: Build Mahout for Spark 2.1/Scala 2.11</h4>

<p><strong>Build Mahout</strong></p>

<p>Follow the standard procedures for building Mahout, except manually set the Spark and Scala versions - the easiest way being:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone http://github.com/apache/mahout
cd mahout
mvn clean package -Dspark.version=2.1.0 -Dscala.version=2.11.8 -Dscala.compat.version=2.11 -DskipTests
</code></pre></div></div>

<p><strong>Download Zeppelin</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd /a/good/place/to/install/
wget http://apache.mirrors.tds.net/zeppelin/zeppelin-0.7.1/zeppelin-0.7.1-bin-all.tgz
tar -xzf zeppelin-0.7.1-bin-all.tgz
cd zeppelin*
bin/zeppelin-daemon.sh start
</code></pre></div></div>

<p>And that’s it. Open a web browser and surf to <a href="http://localhost:8080">http://localhost:8080</a></p>

<p>Proceed to Step 2.</p>

<h4 id="option2-build-zeppelin-for-spark-16scala-210">Option2: Build Zeppelin for Spark 1.6/Scala 2.10</h4>

<p>We’ll use Mahout binaries from Maven, so all you need to do is clone, and build Zeppelin-</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone http://github.com/apache/zeppelin
cd zeppelin
mvn clean package -Pspark1.6 -Pscala2.10 -DskipTests
</code></pre></div></div>

<p>After it builds successfully…</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bin/zeppelin-daemon.sh start
</code></pre></div></div>

<p>And that’s it. Open a web browser and surf to <a href="http://localhost:8080">http://localhost:8080</a></p>

<h3 id="step2-create-the-mahout-spark-interpreter">Step2: Create the Mahout Spark Interpreter</h3>

<p>After opening your web browser and surfing to <a href="http://localhost:8080">http://localhost:8080</a>, click on the <code class="highlighter-rouge">Anonymous</code> 
button on the top right corner, which will open a drop down. Then click <code class="highlighter-rouge">Interpreter</code>.</p>

<p><img src="zeppelin1.png" alt="Screen Shot1" /></p>

<p>At the top right, just below the blue nav bar- you will see two buttons, “Repository” and “+Create”.  Click on “+Create”</p>

<p>The following screen should appear.</p>

<p><img src="zeppelin2.png" alt="Screen Shot2" /></p>

<p>In the <strong>Interpreter Name</strong> enter <code class="highlighter-rouge">mahoutSpark</code> (you can name it whatever you like, but this is what we’ll assume you’ve
named it later in the tutorial)</p>

<p>In the <strong>Interpreter group</strong> drop down, select <code class="highlighter-rouge">spark</code>. A bunch of other settings will now auto-populate.</p>

<p>Scroll to the bottom of the <strong>Properties</strong> list. In the last row, you’ll see two blank boxes.</p>

<p>Add the following properies by clicking the “+” button to the right.</p>

<div class="table-striped">
<table class="table">
    <tr>
        <th>name</th>
        <th>value</th>
    </tr>
    <tr>
        <td>spark.kryo.referenceTracking</td>
        <td>false</td>
    </tr>
    <tr>
        <td>spark.kryo.registrator</td>
        <td>org.apache.mahout.sparkbindings.io.MahoutKryoRegistrator</td>
    </tr>
    <tr>
        <td>spark.kryoserializer.buffer</td>
        <td>32</td>
    </tr>
    <tr>
        <td>spark.kryoserializer.buffer.max</td>
        <td>600m</td>
    </tr>    
    <tr>
        <td>spark.serializer</td>
        <td>org.apache.spark.serializer.KryoSerializer</td>
    </tr> 
</table>
</div>

<h3 id="step-3-add-dependendencies">Step 3: Add Dependendencies</h3>
<p>You’ll also need to add the following <strong>Dependencies</strong>.</p>

<h4 id="if-you-chose-option1-in-step-1">If you chose Option1 in Step 1:</h4>

<p>Where <code class="highlighter-rouge">/path/to/mahout</code> is the path to the directory where you’ve built mahout.</p>

<div class="table-striped">
<table class="table">
    <tr>
        <th>artifact</th>
        <th>exclude</th>
    </tr>
    <tr>
        <td>/path/to/mahout/mahout-math-0.13.0.jar</td>
        <td></td>
    </tr>
    <tr>
        <td>/path/to/mahout/mahout-math-scala_2.11-0.13.0.jar</td>
        <td></td>
    </tr>
    <tr>
        <td>/path/to/mahout/mahout-spark_2.11-0.13.0.jar</td>
        <td></td>
    </tr>  
    <tr>
        <td>/path/to/mahout/mahout-spark_2.11-0.13.0-dependeny-reduced.jar</td>
        <td></td>
    </tr>
</table>
</div>

<h4 id="if-you-chose-option2-in-step-1">If you chose Option2 in Step 1:</h4>

<div class="table-striped">
<table class="table">
    <tr>
        <th>artifact</th>
        <th>exclude</th>
    </tr>
    <tr>
        <td>org.apache.mahout:mahout-math:0.13.0</td>
        <td></td>
    </tr>
    <tr>
        <td>org.apache.mahout:mahout-math-scala_2.10:0.13.0</td>
        <td></td>
    </tr>
    <tr>
        <td>org.apache.mahout:mahout-spark_2.10:0.13.0</td>
        <td></td>
    </tr>
     <tr>
         <td>org.apache.mahout:mahout-native-viennacl-omp_2.10:0.13.0</td>
         <td></td>
     </tr> 

</table>
</div>

<p><em><strong>OPTIONALLY</strong></em> You can add <strong>one</strong> of the following artifacts for CPU/GPU acceleration.</p>

<div class="table-striped">
<table class="table">
    <tr>
        <th>artifact</th>
        <th>exclude</th>
        <th>type of native solver</th>
    </tr>
     <tr>
         <td>org.apache.mahout:mahout-native-viennacl_2.10:0.13.0</td>
         <td></td>
         <td>ViennaCL GPU Accelerated</td>
     </tr> 
     <tr>
         <td>org.apache.mahout:mahout-native-viennacl-omp_2.10:0.13.0</td>
         <td></td>
         <td>ViennaCL-OMP CPU Accelerated (use this if you don't have a good graphics card)</td>
     </tr> 
</table>
</div>

<p>Make sure to click “Save” and you’re all set.</p>

<h3 id="step-4-rock-and-roll">Step 4. Rock and Roll.</h3>

<p>Mahout in Zeppelin, unlike the Mahout Shell, won’t take care of importing the Mahout libraries or creating the 
<code class="highlighter-rouge">MahoutSparkContext</code>, we need to do that manually. This is easy though.  When ever you start Zeppelin (or restart) the 
Mahout interpreter, you’ll need to run the following code first:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>%sparkMahout

import org.apache.mahout.math._
import org.apache.mahout.math.scalabindings._
import org.apache.mahout.math.drm._
import org.apache.mahout.math.scalabindings.RLikeOps._
import org.apache.mahout.math.drm.RLikeDrmOps._
import org.apache.mahout.sparkbindings._

implicit val sdc: org.apache.mahout.sparkbindings.SparkDistributedContext = sc2sdc(sc)
</code></pre></div></div>

<p>At this point, you have a Zeppelin Interpreter which will behave like the <code class="highlighter-rouge">$MAHOUT_HOME/bin/mahout spark-shell</code></p>

<p>Except, much much more.</p>

<p>At the begining I mentioned a few important features of Zeppelin, that we could leverage to use Zeppelin for visualizatoins.</p>

<h4 id="example-1-visualizing-a-matrix-sample-with-r">Example 1: Visualizing a Matrix (Sample) with R</h4>

<p>In Mahout we can use <code class="highlighter-rouge">Matrices.symmetricUniformView</code> to create a Gaussian Matrix.</p>

<p>We can use <code class="highlighter-rouge">.mapBlock</code> and some clever code to create a 3D Gausian Matrix.</p>

<p>We can use <code class="highlighter-rouge">.drmSampleToTsv</code> to take a sample of the matrix and turn it in to a tab seperated string. We take a sample of 
 the matrix because, since we are dealing with “big” data, we wouldn’t want to try to collect and plot the entire matrix, 
 however, IF we knew we had a small matrix and we DID want to sample the entire thing, then we could sample <code class="highlighter-rouge">100.0</code> e.g. 100%.</p>

<p>Finally we use <code class="highlighter-rouge">z.put(...)</code> to put a variable into Zeppelin’s <code class="highlighter-rouge">ResourcePool</code> a block of memory shared by all interpreters.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>%sparkMahout

val mxRnd3d = Matrices.symmetricUniformView(5000, 3, 1234)
val drmRand3d = drmParallelize(mxRnd3d)

val drmGauss = drmRand3d.mapBlock() {case (keys, block) =&gt;
  val blockB = block.like()
  for (i &lt;- 0 until block.nrow) {
    val x: Double = block(i, 0)
    val y: Double = block(i, 1)
    val z: Double = block(i, 2)

    blockB(i, 0) = x
    blockB(i, 1) = y
    blockB(i, 2) = Math.exp(-((Math.pow(x, 2)) + (Math.pow(y, 2)))/2)
  }
  keys -&gt; blockB
}

resourcePool.put("gaussDrm", drm.drmSampleToTSV(drmGauss, 50.0))
</code></pre></div></div>

<p>Here we sample 50% of the matrix and put it in the <code class="highlighter-rouge">ResourcePool</code> under a variable named “gaussDrm”.</p>

<p>Now, for the exciting part. Scala doesn’t have a lot of great graphing utilities. But you know who does? R and Python. So
instead of trying to akwardly visualize our data using Scala, let’s just use R and Python.</p>

<p>We start the Spark R interpreter (we do this because the regular R interpreter doesn’t have access to the resource pools).</p>

<p>We <code class="highlighter-rouge">z.get</code> the variable we just put in.</p>

<p>We use R’s <code class="highlighter-rouge">read.table</code> to read the string- this is very similar to how we would read a tsv file in R.</p>

<p>Then we plot the data using the R <code class="highlighter-rouge">scatterplot3d</code> package.</p>

<p><strong>Note</strong> you may need to install <code class="highlighter-rouge">scatterplot3d</code>. In Ubuntu, do this with <code class="highlighter-rouge">sudo apt-get install r-cran-scatterplot3d</code></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>%spark.r {"imageWidth": "400px"}

library(scatterplot3d)


gaussStr = z.get("gaussDrm")
data &lt;- read.table(text= gaussStr, sep="\t", header=FALSE)

scatterplot3d(data, color="green")
</code></pre></div></div>

<p><img src="zeppelin3.png" alt="A neat plot" /></p>
