<h1 id="mahout-samsaras-distributed-linear-algebra-dsl-reference">Mahout-Samsara’s Distributed Linear Algebra DSL Reference</h1>

<p><strong>Note: this page is meant only as a quick reference to Mahout-Samsara’s R-Like DSL semantics.  For more information, including information on Mahout-Samsara’s Algebraic Optimizer please see: <a href="http://mahout.apache.org/users/sparkbindings/ScalaSparkBindings.pdf">Mahout Scala Bindings and Mahout Spark Bindings for Linear Algebra Subroutines</a>.</strong></p>

<p>The subjects of this reference are solely applicable to Mahout-Samsara’s <strong>DRM</strong> (distributed row matrix).</p>

<p>In this reference, DRMs will be denoted as e.g. <code class="highlighter-rouge">A</code>, and in-core matrices as e.g. <code class="highlighter-rouge">inCoreA</code>.</p>

<h4 id="imports">Imports</h4>

<p>The following imports are used to enable seamless in-core and distributed algebraic DSL operations:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.apache.mahout.math._
import scalabindings._
import RLikeOps._
import drm._
import RLikeDRMOps._
</code></pre></div></div>

<p>If working with mixed scala/java code:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import collection._
import JavaConversions._
</code></pre></div></div>

<p>If you are working with Mahout-Samsara’s Spark-specific operations e.g. for context creation:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.apache.mahout.sparkbindings._
</code></pre></div></div>

<p>The Mahout shell does all of these imports automatically.</p>

<h4 id="drm-persistence-operators">DRM Persistence operators</h4>

<p><strong>Mahout-Samsara’s DRM persistance to HDFS is compatible with all Mahout-MapReduce algorithms such as seq2sparse.</strong></p>

<p>Loading a DRM from (HD)FS:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drmDfsRead(path = hdfsPath)
</code></pre></div></div>

<p>Parallelizing from an in-core matrix:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val inCoreA = (dense(1, 2, 3), (3, 4, 5))
val A = drmParallelize(inCoreA)
</code></pre></div></div>

<p>Creating an empty DRM:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val A = drmParallelizeEmpty(100, 50)
</code></pre></div></div>

<p>Collecting to driver’s jvm in-core:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val inCoreA = A.collect
</code></pre></div></div>

<p><strong>Warning: The collection of distributed matrices happens implicitly whenever conversion to an in-core (o.a.m.math.Matrix) type is required. E.g.:</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val inCoreA: Matrix = ...
val drmB: DrmLike[Int] =...
val inCoreC: Matrix = inCoreA %*%: drmB
</code></pre></div></div>

<p><strong>implies (incoreA %*%: drmB).collect</strong></p>

<p>Collecting to (HD)FS as a Mahout’s DRM formatted file:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A.dfsWrite(path = hdfsPath)
</code></pre></div></div>

<h4 id="logical-algebraic-operators-on-drm-matrices">Logical algebraic operators on DRM matrices:</h4>

<p>A logical set of operators are defined for distributed matrices as a subset of those defined for in-core matrices.  In particular, since all distributed matrices are immutable, there are no assignment operators (e.g. <strong>A += B</strong>)
<em>Note: please see: <a href="http://mahout.apache.org/users/sparkbindings/ScalaSparkBindings.pdf">Mahout Scala Bindings and Mahout Spark Bindings for Linear Algebra Subroutines</a> for information on Mahout-Samsars’s Algebraic Optimizer, and translation from logical operations to a physical plan for the back end.</em></p>

<p>Cache a DRM and trigger an optimized physical plan:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drmA.checkpoint(CacheHint.MEMORY_AND_DISK)
</code></pre></div></div>

<p>Other valid caching Instructions:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drmA.checkpoint(CacheHint.NONE)
drmA.checkpoint(CacheHint.DISK_ONLY)
drmA.checkpoint(CacheHint.DISK_ONLY_2)
drmA.checkpoint(CacheHint.MEMORY_ONLY)
drmA.checkpoint(CacheHint.MEMORY_ONLY_2)
drmA.checkpoint(CacheHint.MEMORY_ONLY_SER
drmA.checkpoint(CacheHint.MEMORY_ONLY_SER_2)
drmA.checkpoint(CacheHint.MEMORY_AND_DISK_2)
drmA.checkpoint(CacheHint.MEMORY_AND_DISK_SER)
drmA.checkpoint(CacheHint.MEMORY_AND_DISK_SER_2)
</code></pre></div></div>

<p><em>Note: Logical DRM operations are lazily computed.  Currently the actual computations and optional caching will be triggered by dfsWrite(…), collect(…) and blockify(…).</em></p>

<p>Transposition:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A.t
</code></pre></div></div>

<p>Elementwise addition <em>(Matrices of identical geometry and row key types)</em>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A + B
</code></pre></div></div>

<p>Elementwise subtraction <em>(Matrices of identical geometry and row key types)</em>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A - B
</code></pre></div></div>

<p>Elementwise multiplication (Hadamard) <em>(Matrices of identical geometry and row key types)</em>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A * B
</code></pre></div></div>

<p>Elementwise division <em>(Matrices of identical geometry and row key types)</em>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A / B
</code></pre></div></div>

<p><strong>Elementwise operations involving one in-core argument (int-keyed DRMs only)</strong>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A + inCoreB
A - inCoreB
A * inCoreB
A / inCoreB
A :+ inCoreB
A :- inCoreB
A :* inCoreB
A :/ inCoreB
inCoreA +: B
inCoreA -: B
inCoreA *: B
inCoreA /: B
</code></pre></div></div>

<p>Note the Spark associativity change (e.g. <code class="highlighter-rouge">A *: inCoreB</code> means <code class="highlighter-rouge">B.leftMultiply(A</code>), same as when both arguments are in core). Whenever operator arguments include both in-core and out-of-core arguments, the operator can only be associated with the out-of-core (DRM) argument to support the distributed implementation.</p>

<p><strong>Matrix-matrix multiplication %*%</strong>:</p>

<p><code class="highlighter-rouge">\(\mathbf{M}=\mathbf{AB}\)</code></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A %*% B
A %*% inCoreB
A %*% inCoreDiagonal
A %*%: B
</code></pre></div></div>

<p><em>Note: same as above, whenever operator arguments include both in-core and out-of-core arguments, the operator can only be associated with the out-of-core (DRM) argument to support the distributed implementation.</em></p>

<p><strong>Matrix-vector multiplication %*%</strong>
Currently we support a right multiply product of a DRM and an in-core Vector(<code class="highlighter-rouge">\(\mathbf{Ax}\)</code>) resulting in a single column DRM, which then can be collected in front (usually the desired outcome):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val Ax = A %*% x
val inCoreX = Ax.collect(::, 0)
</code></pre></div></div>

<p><strong>Matrix-scalar +,-,*,/</strong>
Elementwise operations of every matrix element and a scalar:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A + 5.0
A - 5.0
A :- 5.0
5.0 -: A
A * 5.0
A / 5.0
5.0 /: a
</code></pre></div></div>

<p>Note that <code class="highlighter-rouge">5.0 -: A</code> means <code class="highlighter-rouge">\(m_{ij} = 5 - a_{ij}\)</code> and <code class="highlighter-rouge">5.0 /: A</code> means <code class="highlighter-rouge">\(m_{ij} = \frac{5}{a{ij}}\)</code> for all elements of the result.</p>

<h4 id="slicing">Slicing</h4>

<p>General slice:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A(100 to 200, 100 to 200)
</code></pre></div></div>

<p>Horizontal Block:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A(::, 100 to 200)
</code></pre></div></div>

<p>Vertical Block:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A(100 to 200, ::)
</code></pre></div></div>

<p><em>Note: if row range is not all-range (::) the the DRM must be <code class="highlighter-rouge">Int</code>-keyed.  General case row slicing is not supported by DRMs with key types other than <code class="highlighter-rouge">Int</code></em>.</p>

<h4 id="stitching">Stitching</h4>

<p>Stitch side by side (cbind R semantics):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val drmAnextToB = drmA cbind drmB
</code></pre></div></div>

<p>Stitch side by side (Scala):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val drmAnextToB = drmA.cbind(drmB)
</code></pre></div></div>

<p>Analogously, vertical concatenation is available via <strong>rbind</strong></p>

<h4 id="custom-pipelines-on-blocks">Custom pipelines on blocks</h4>
<p>Internally, Mahout-Samsara’s DRM is represented as a distributed set of vertical (Key, Block) tuples.</p>

<p><strong>drm.mapBlock(…)</strong>:</p>

<p>The DRM operator <code class="highlighter-rouge">mapBlock</code> provides transformational access to the distributed vertical blockified tuples of a matrix (Row-Keys, Vertical-Matrix-Block).</p>

<p>Using <code class="highlighter-rouge">mapBlock</code> to add 1.0 to a DRM:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val inCoreA = dense((1, 2, 3), (2, 3 , 4), (3, 4, 5))
val drmA = drmParallelize(inCoreA)
val B = A.mapBlock() {
    case (keys, block) =&gt; keys -&gt; (block += 1.0)
}
</code></pre></div></div>

<h4 id="broadcasting-vectors-and-matrices-to-closures">Broadcasting Vectors and matrices to closures</h4>
<p>Generally we can create and use one-way closure attributes to be used on the back end.</p>

<p>Scalar matrix multiplication:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val factor: Int = 15
val drm2 = drm1.mapBlock() {
    case (keys, block) =&gt; block *= factor
    keys -&gt; block
}
</code></pre></div></div>

<p><strong>Closure attributes must be java-serializable. Currently Mahout’s in-core Vectors and Matrices are not java-serializable, and must be broadcast to the closure using <code class="highlighter-rouge">drmBroadcast(...)</code></strong>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val v: Vector ...
val bcastV = drmBroadcast(v)
val drm2 = drm1.mapBlock() {
    case (keys, block) =&gt;
        for(row &lt;- 0 until block.nrow) block(row, ::) -= bcastV
    keys -&gt; block    
}
</code></pre></div></div>

<h4 id="computations-providing-ad-hoc-summaries">Computations providing ad-hoc summaries</h4>

<p>Matrix cardinality:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drmA.nrow
drmA.ncol
</code></pre></div></div>

<p><em>Note: depending on the stage of optimization, these may trigger a computational action.  I.e. if one calls <code class="highlighter-rouge">nrow()</code> n times, then the back end will actually recompute <code class="highlighter-rouge">nrow</code> n times.</em></p>

<p>Means and sums:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drmA.colSums
drmA.colMeans
drmA.rowSums
drmA.rowMeans
</code></pre></div></div>

<p><em>Note: These will always trigger a computational action.  I.e. if one calls <code class="highlighter-rouge">colSums()</code> n times, then the back end will actually recompute <code class="highlighter-rouge">colSums</code> n times.</em></p>

<h4 id="distributed-matrix-decompositions">Distributed Matrix Decompositions</h4>

<p>To import the decomposition package:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.apache.mahout.math._
import decompositions._
</code></pre></div></div>

<p>Distributed thin QR:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val (drmQ, incoreR) = dqrThin(drmA)
</code></pre></div></div>

<p>Distributed SSVD:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val (drmU, drmV, s) = dssvd(drmA, k = 40, q = 1)
</code></pre></div></div>

<p>Distributed SPCA:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val (drmU, drmV, s) = dspca(drmA, k = 30, q = 1)
</code></pre></div></div>

<p>Distributed regularized ALS:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val (drmU, drmV, i) = dals(drmA,
                        k = 50,
                        lambda = 0.0,
                        maxIterations = 10,
                        convergenceThreshold = 0.10))
</code></pre></div></div>

<h4 id="adjusting-parallelism-of-computations">Adjusting parallelism of computations</h4>

<p>Set the minimum parallelism to 100 for computations on <code class="highlighter-rouge">drmA</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drmA.par(min = 100)
</code></pre></div></div>

<p>Set the exact parallelism to 100 for computations on <code class="highlighter-rouge">drmA</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drmA.par(exact = 100)
</code></pre></div></div>

<p>Set the engine specific automatic parallelism adjustment for computations on <code class="highlighter-rouge">drmA</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drmA.par(auto = true)
</code></pre></div></div>

<h4 id="retrieving-the-engine-specific-data-structure-backing-the-drm">Retrieving the engine specific data structure backing the DRM:</h4>

<p><strong>A Spark RDD:</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val myRDD = drmA.checkpoint().rdd
</code></pre></div></div>

<p><strong>An H2O Frame and Key Vec:</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val myFrame = drmA.frame
val myKeys = drmA.keys
</code></pre></div></div>

<p><strong>A Flink DataSet:</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val myDataSet = drmA.ds
</code></pre></div></div>

<p>For more information including information on Mahout-Samsara’s Algebraic Optimizer and in-core Linear algebra bindings see: <a href="http://mahout.apache.org/users/sparkbindings/ScalaSparkBindings.pdf">Mahout Scala Bindings and Mahout Spark Bindings for Linear Algebra Subroutines</a></p>

