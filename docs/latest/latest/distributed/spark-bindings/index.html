<h1 id="scala--spark-bindings">Scala &amp; Spark Bindings:</h1>
<p><em>Bringing algebraic semantics</em></p>

<h2 id="what-is-scala--spark-bindings">What is Scala &amp; Spark Bindings?</h2>

<p>In short, Scala &amp; Spark Bindings for Mahout is Scala DSL and algebraic optimizer of something like this (actual formula from <strong>(d)spca</strong>)</p>

<p><code class="highlighter-rouge">\[\mathbf{G}=\mathbf{B}\mathbf{B}^{\top}-\mathbf{C}-\mathbf{C}^{\top}+\mathbf{s}_{q}\mathbf{s}_{q}^{\top}\boldsymbol{\xi}^{\top}\boldsymbol{\xi}\]</code></p>

<p>bound to in-core and distributed computations (currently, on Apache Spark).</p>

<p>Mahout Scala &amp; Spark Bindings expression of the above:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    val g = bt.t %*% bt - c - c.t + (s_q cross s_q) * (xi dot xi)
</code></pre></div></div>

<p>The main idea is that a scientist writing algebraic expressions cannot care less of distributed 
operation plans and works <strong>entirely on the logical level</strong> just like he or she would do with R.</p>

<p>Another idea is decoupling logical expression from distributed back-end. As more back-ends are added, 
this implies <strong>“write once, run everywhere”</strong>.</p>

<p>The linear algebra side works with scalars, in-core vectors and matrices, and Mahout Distributed
Row Matrices (DRMs).</p>

<p>The ecosystem of operators is built in the R’s image, i.e. it follows R naming such as %*%, 
colSums, nrow, length operating over vectors or matices.</p>

<p>Important part of Spark Bindings is expression optimizer. It looks at expression as a whole 
and figures out how it can be simplified, and which physical operators should be picked. For example,
there are currently about 5 different physical operators performing DRM-DRM multiplication
picked based on matrix geometry, distributed dataset partitioning, orientation etc. 
If we count in DRM by in-core combinations, that would be another 4, i.e. 9 total – all of it for just 
simple x %*% y logical notation.</p>

<p>Please refer to the documentation for details.</p>

<h2 id="status">Status</h2>

<p>This environment addresses mostly R-like Linear Algebra optmizations for 
Spark, Flink and H20.</p>

<h2 id="documentation">Documentation</h2>

<ul>
  <li>Scala and Spark bindings manual: <a href="http://apache.github.io/mahout/doc/ScalaSparkBindings.html">web</a>, <a href="ScalaSparkBindings.pdf">pdf</a>, <a href="MahoutScalaAndSparkBindings.pptx">pptx</a></li>
  <li><a href="faq.html">Spark Bindings FAQ</a>
<!-- dead link* Overview blog on 0.10.x releases: [blog](http://www.weatheringthroughtechdays.com/2015/04/mahout-010x-first-mahout-release-as.html) --></li>
</ul>

<h2 id="distributed-methods-and-solvers-using-bindings">Distributed methods and solvers using Bindings</h2>

<ul>
  <li>In-core (<a href="https://github.com/apache/mahout/blob/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/SSVD.scala">ssvd</a>) and Distributed (<a href="https://github.com/apache/mahout/blob/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DSSVD.scala">dssvd</a>) Stochastic SVD – guinea pigs – see the bindings manual</li>
  <li>In-core (<a href="https://github.com/apache/mahout/blob/trunk/math-scala/src/main/scala/org/apache/mahout/math/scalabindings/SSVD.scala">spca</a>) and Distributed (<a href="https://github.com/apache/mahout/blob/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DSPCA.scala">dspca</a>) Stochastic PCA – guinea pigs – see the bindings manual</li>
  <li>Distributed thin QR decomposition (<a href="https://github.com/apache/mahout/blob/trunk/spark/src/main/scala/org/apache/mahout/sparkbindings/decompositions/DQR.scala">dqrThin</a>) – guinea pig – see the bindings manual</li>
  <li><a href="https://mahout.apache.org/users/basics/algorithms.html">Current list of algorithms</a></li>
</ul>

<h2 id="reading-rdds-and-dataframes-into-drms">Reading RDDs and DataFrames into DRMs</h2>
<p>TODO</p>

<p>TODO: Do we still want this? (I don’t think so…)</p>
<h2 id="related-history-of-note">Related history of note</h2>

<ul>
  <li>CLI and Driver for Spark version of item similarity – <a href="https://issues.apache.org/jira/browse/MAHOUT-1541">MAHOUT-1541</a></li>
  <li>Command line interface for generalizable Spark pipelines – <a href="https://issues.apache.org/jira/browse/MAHOUT-1569">MAHOUT-1569</a></li>
  <li>Cooccurrence Analysis / Item-based Recommendation – <a href="https://issues.apache.org/jira/browse/MAHOUT-1464">MAHOUT-1464</a></li>
  <li>Spark Bindings – <a href="https://issues.apache.org/jira/browse/MAHOUT-1346">MAHOUT-1346</a></li>
  <li>Scala Bindings – <a href="https://issues.apache.org/jira/browse/MAHOUT-1297">MAHOUT-1297</a></li>
  <li>Interactive Scala &amp; Spark Bindings Shell &amp; Script processor – <a href="https://issues.apache.org/jira/browse/MAHOUT-1489">MAHOUT-1489</a></li>
  <li>OLS tutorial using Mahout shell – <a href="https://issues.apache.org/jira/browse/MAHOUT-1542">MAHOUT-1542</a></li>
  <li>Full abstraction of DRM apis and algorithms from a distributed engine – <a href="https://issues.apache.org/jira/browse/MAHOUT-1529">MAHOUT-1529</a></li>
  <li>Port Naive Bayes – <a href="https://issues.apache.org/jira/browse/MAHOUT-1493">MAHOUT-1493</a></li>
</ul>

<h2 id="work-in-progress">Work in progress</h2>
<ul>
  <li>
    <p>Text-delimited files for input and output – <a href="https://issues.apache.org/jira/browse/MAHOUT-1568">MAHOUT-1568</a>
<!-- * Weighted (Implicit Feedback) ALS -- [MAHOUT-1365](https://issues.apache.org/jira/browse/MAHOUT-1365) -->
<!--* Data frame R-like bindings -- [MAHOUT-1490](https://issues.apache.org/jira/browse/MAHOUT-1490) --></p>
  </li>
  <li>
    <p><em>Your issue here!</em></p>
  </li>
</ul>

<!-- ## Stuff wanted: 
* Data frame R-like bindings (similarly to linalg bindings)
* Stat R-like bindings (perhaps we can just adapt to commons.math stat)
* **BYODMs:** Bring Your Own Distributed Method on SparkBindings! 
* In-core jBlas matrix adapter
* In-core GPU matrix adapters -->

