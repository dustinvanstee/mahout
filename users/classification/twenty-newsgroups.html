

<!DOCTYPE html>
<!--

    Licensed to the Apache Software Foundation (ASF) under one or more
    contributor license agreements.  See the NOTICE file distributed with
    this work for additional information regarding copyright ownership.
    The ASF licenses this file to You under the Apache License, Version 2.0
    (the "License"); you may not use this file except in compliance with
    the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
-->

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Apache Mahout: Scalable machine learning and data mining</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="Distribution" content="Global">
  <meta name="Robots" content="index,follow">
  <meta name="keywords" content="apache, apache hadoop, apache lucene,
        business data mining, cluster analysis,
        collaborative filtering, data extraction, data filtering, data framework, data integration,
        data matching, data mining, data mining algorithms, data mining analysis, data mining data,
        data mining introduction, data mining software,
        data mining techniques, data representation, data set, datamining,
        feature extraction, fuzzy k means, genetic algorithm, hadoop,
        hierarchical clustering, high dimensional, introduction to data mining, kmeans,
        knowledge discovery, learning approach, learning approaches, learning methods,
        learning techniques, lucene, machine learning, machine translation, mahout apache,
        mahout taste, map reduce hadoop, mining data, mining methods, naive bayes,
        natural language processing,
        supervised, text mining, time series data, unsupervised, web data mining">
  <link rel="shortcut icon" type="image/x-icon" href="https://mahout.apache.org/images/favicon.ico">
  <!--<script type="text/javascript" src="/js/prototype.js"></script>-->
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/prototype/1.7.2.0/prototype.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/effects.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/search.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/slides.js"></script>

  <link href="/assets/themes/mahout-retro/css/bootstrap.min.css" rel="stylesheet" media="screen">
  <link href="/assets/themes/mahout-retro/css/bootstrap-responsive.css" rel="stylesheet">
  <link rel="stylesheet" href="/assets/themes/mahout-retro/css/global.css" type="text/css">

  <!-- mathJax stuff -- use `\(...\)` for inline style math in markdown -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
  </script>
  <script type="text/javascript">
    var mathjax = document.createElement('script'); 
    mathjax.type = 'text/javascript'; 
    mathjax.async = true;

    mathjax.src = ('https:' == document.location.protocol) ?
        'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML' : 
        'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
	
	  var s = document.getElementsByTagName('script')[0]; 
    s.parentNode.insertBefore(mathjax, s);
  </script>
</head>

<body id="home" data-twttr-rendered="true">
  <div id="wrap">
   <div id="header">
    <div id="logo"><a href="/"><img src="/assets/img/mahout-logo-brudman.png" alt="Logos for Mahout and Apache Software Foundation" /></a></div>
  <div id="search">
    <form id="search-form" action="http://www.google.com/search" method="get" class="navbar-search pull-right">    
      <input value="http://mahout.apache.org" name="sitesearch" type="hidden">
      <input class="search-query" name="q" id="query" type="text">
      <input id="submission" type="image" src="/assets/img/mahout-lupe.png" alt="Search" />
    </form>
  </div>
 
    <div class="navbar navbar-inverse" style="position:absolute;top:133px;padding-right:0px;padding-left:0px;">
      <div class="navbar-inner" style="border: none; background: #999; border: none; border-radius: 0px;">
        <div class="container">
          <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!-- <a class="brand" href="#">Apache Community Development Project</a> -->
            <!--<div class="nav-collapse collapse">-->
<div class="collapse navbar-collapse" id="main-navbar">
    <ul class="nav navbar-nav">
        <!-- <li><a href="/">Home</a></li> -->
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">General<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/general/downloads.html">Downloads</a>
                <li><a href="/general/who-we-are.html">Who we are</a>
                <li><a href="/general/mailing-lists,-irc-and-archives.html">Mailing Lists</a>
                <li><a href="/general/release-notes.html">Release Notes</a>
                <li><a href="/general/books-tutorials-and-talks.html">Books, Tutorials, Talks</a></li>
                <li><a href="/general/powered-by-mahout.html">Powered By Mahout</a>
                <li><a href="/general/professional-support.html">Professional Support</a>
                <li class="divider"></li>
                <li class="nav-header">Resources</li>
                <li><a href="/general/reference-reading.html">Reference Reading</a>
                <li><a href="/general/faq.html">FAQ</a>
                <li class="divider"></li>
                <li class="nav-header">Legal</li>
                <li><a href="http://www.apache.org/licenses/">License</a></li>
                <li><a href="http://www.apache.org/security/">Security</a></li>
                <li><a href="/general/privacy-policy.html">Privacy Policy</a>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Developers<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/developers/developer-resources.html">Developer resources</a></li>
                <li><a href="/developers/version-control.html">Version control</a></li>
                <li><a href="/developers/buildingmahout.html">Build from source</a></li>
                <li><a href="/developers/issue-tracker.html">Issue tracker</a></li>
                <li><a href="https://builds.apache.org/job/Mahout-Quality/" target="_blank">Code quality reports</a></li>
                <li class="divider"></li>
                <li class="nav-header">Contributions</li>
                <li><a href="/developers/how-to-contribute.html">How to contribute</a></li>
                <li><a href="/developers/how-to-become-a-committer.html">How to become a committer</a></li>
                <li><a href="/developers/gsoc.html">GSoC</a></li>
                <li class="divider"></li>
                <li class="nav-header">For committers</li>
                <li><a href="/developers/how-to-update-the-website.html">How to update the website</a></li>
                <li><a href="/developers/patch-check-list.html">Patch check list</a></li>
                <li><a href="/developers/github.html">Handling Github PRs</a></li>
                <li><a href="/developers/how-to-release.html">How to release</a></li>
                <li><a href="/developers/thirdparty-dependencies.html">Third party dependencies</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Mahout-Samsara<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/sparkbindings/home.html">Scala &amp; Spark Bindings Overview</a></li>
                <li><a href="/users/sparkbindings/faq.html">FAQ</a></li>
                <li><a href="/users/flinkbindings/playing-with-samsara-flink.html">Flink Bindings Overview</a></li>
                <li class="nav-header">Engines</li>
                <li><a href="/users/sparkbindings/home.html">Spark</a></li>
                <li><a href="/users/environment/h2o-internals.html">H2O</a></li>
                <li><a href="/users/flinkbindings/flink-internals.html">Flink</a></li>
                <li class="nav-header">References</li>
                <li><a href="/users/environment/in-core-reference.html">In-Core Algebraic DSL Reference</a></li>
                <li><a href="/users/environment/out-of-core-reference.html">Distributed Algebraic DSL Reference</a></li>
                <li class="nav-header">Tutorials</li>
                <li><a href="/users/sparkbindings/play-with-shell.html">Playing with Mahout's Spark Shell</a></li>
                <li><a href="/users/environment/how-to-build-an-app.html">How to build an app</a></li>
                <li><a href="/users/environment/classify-a-doc-from-the-shell.html">Building a text classifier in Mahout's Spark Shell</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Algorithms<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/basics/algorithms.html">List of algorithms</a>
                <li class="nav-header">Distributed Matrix Decomposition</li>
                <li><a href="/users/algorithms/d-qr.html">Cholesky QR</a></li>
                <li><a href="/users/algorithms/d-ssvd.html">SSVD</a></li>
                <li><a href="/users/algorithms/d-als.html">Distributed ALS</a></li>
                <li><a href="/users/algorithms/d-spca.html">SPCA</a></li>
                <li class="nav-header">Recommendations</li>
                <li><a href="/users/algorithms/recommender-overview.html">Recommender Overview</a></li>
                <li><a href="/users/algorithms/intro-cooccurrence-spark.html">Intro to cooccurrence-based<br/> recommendations with Spark</a></li>
                <li class="nav-header">Classification</li>
                <li><a href="/users/algorithms/spark-naive-bayes.html">Spark Naive Bayes</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">MapReduce Basics<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/basics/algorithms.html">List of algorithms</a>
                <li><a href="/users/basics/quickstart.html">Overview</a>
                <li class="divider"></li>
                <li class="nav-header">Working with text</li>
                <li><a href="/users/basics/creating-vectors-from-text.html">Creating vectors from text</a>
                <li><a href="/users/basics/collocations.html">Collocations</a>
                <li class="divider"></li>
                <li class="nav-header">Dimensionality reduction</li>
                <li><a href="/users/dim-reduction/dimensional-reduction.html">Singular Value Decomposition</a></li>
                <li><a href="/users/dim-reduction/ssvd.html">Stochastic SVD</a></li>
                <li class="divider"></li>
                <li class="nav-header">Topic Models</li>
                <li><a href="/users/clustering/latent-dirichlet-allocation.html">Latent Dirichlet Allocation</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Mahout MapReduce<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li class="nav-header">Classification</li>
                <li><a href="/users/classification/bayesian.html">Naive Bayes</a></li>
                <li><a href="/users/classification/hidden-markov-models.html">Hidden Markov Models</a></li>
                <li><a href="/users/classification/logistic-regression.html">Logistic Regression (Single Machine)</a></li>
                <li><a href="/users/classification/partial-implementation.html">Random Forest</a></li>
                <li class="nav-header">Classification Examples</li>
                <li><a href="/users/classification/breiman-example.html">Breiman example</a></li>
                <li><a href="/users/classification/twenty-newsgroups.html">20 newsgroups example</a></li>
                <li><a href="/users/classification/bankmarketing-example.html">SGD classifier bank marketing</a></li>
                <li><a href="/users/classification/wikipedia-classifier-example.html">Wikipedia XML parser and classifier</a></li>
                <li class="nav-header">Clustering</li>
                <li><a href="/users/clustering/k-means-clustering.html">k-Means</a></li>
                <li><a href="/users/clustering/canopy-clustering.html">Canopy</a></li>
                <li><a href="/users/clustering/fuzzy-k-means.html">Fuzzy k-Means</a></li>
                <li><a href="/users/clustering/streaming-k-means.html">Streaming KMeans</a></li>
                <li><a href="/users/clustering/spectral-clustering.html">Spectral Clustering</a></li>
                <li class="nav-header">Clustering Commandline usage</li>
                <li><a href="/users/clustering/k-means-commandline.html">Options for k-Means</a></li>
                <li><a href="/users/clustering/canopy-commandline.html">Options for Canopy</a></li>
                <li><a href="/users/clustering/fuzzy-k-means-commandline.html">Options for Fuzzy k-Means</a></li>
                <li class="nav-header">Clustering Examples</li>
                <li><a href="/users/clustering/clustering-of-synthetic-control-data.html">Synthetic data</a></li>
                <li class="nav-header">Cluster Post processing</li>
                <li><a href="/users/clustering/cluster-dumper.html">Cluster Dumper tool</a></li>
                <li><a href="/users/clustering/visualizing-sample-clusters.html">Cluster visualisation</a></li>
                <li class="nav-header">Recommendations</li>
                <li><a href="/users/recommender/recommender-first-timer-faq.html">First Timer FAQ</a></li>
                <li><a href="/users/recommender/userbased-5-minutes.html">A user-based recommender <br/>in 5 minutes</a></li>
                <li><a href="/users/recommender/matrix-factorization.html">Matrix factorization-based<br/> recommenders</a></li>
                <li><a href="/users/recommender/recommender-documentation.html">Overview</a></li>
                <li><a href="/users/recommender/intro-itembased-hadoop.html">Intro to item-based recommendations<br/> with Hadoop</a></li>
                <li><a href="/users/recommender/intro-als-hadoop.html">Intro to ALS recommendations<br/> with Hadoop</a></li>
            </ul>
        </li>
        <!--  <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Recommendations<b class="caret"></b></a>
          <ul class="dropdown-menu">

          </ul> -->
        </li>
    </ul>
</div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

</div>

 <div id="sidebar">
  <div id="sidebar-wrap">
    <h2>Twitter</h2>
	<ul class="sidemenu">
		<li>
<a class="twitter-timeline" href="https://twitter.com/ApacheMahout" data-widget-id="422861673444028416">Tweets by @ApacheMahout</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</li>
	</ul>
    <h2>Apache Software Foundation</h2>
    <ul class="sidemenu">
      <li><a href="http://www.apache.org/foundation/how-it-works.html">How the ASF works</a></li>
      <li><a href="http://www.apache.org/foundation/getinvolved.html">Get Involved</a></li>
      <li><a href="http://www.apache.org/dev/">Developer Resources</a></li>
      <li><a href="http://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
      <li><a href="http://www.apache.org/foundation/thanks.html">Thanks</a></li>
    </ul>
    <h2>Related Projects</h2>
    <ul class="sidemenu">
      <li><a href="http://lucene.apache.org/">Apache Lucene</a></li>
      <li><a href="http://hadoop.apache.org/">Apache Hadoop</a></li>
      <li><a href="http://bigtop.apache.org/">Apache Bigtop</a></li>
      <li><a href="http://spark.apache.org/">Apache Spark</a></li>
	  <li><a href="http://flink.apache.org/">Apache Flink</a></li>
    </ul>
  </div>
</div>

  <div id="content-wrap" class="clearfix">
   <div id="main">

    <p><a name="TwentyNewsgroups-TwentyNewsgroupsClassificationExample"></a></p>
<h2 id="twenty-newsgroups-classification-example">Twenty Newsgroups Classification Example</h2>

<p><a name="TwentyNewsgroups-Introduction"></a></p>
<h2 id="introduction">Introduction</h2>

<p>The 20 newsgroups dataset is a collection of approximately 20,000
newsgroup documents, partitioned (nearly) evenly across 20 different
newsgroups. The 20 newsgroups collection has become a popular data set for
experiments in text applications of machine learning techniques, such as
text classification and text clustering. We will use the <a href="http://mahout.apache.org/users/mapreduce/classification/bayesian.html">Mahout CBayes</a>
classifier to create a model that would classify a new document into one of
the 20 newsgroups.</p>

<p><a name="TwentyNewsgroups-Prerequisites"></a></p>
<h3 id="prerequisites">Prerequisites</h3>

<ul>
  <li>Mahout has been downloaded (<a href="https://mahout.apache.org/general/downloads.html">instructions here</a>)</li>
  <li>Maven is available</li>
  <li>Your environment has the following variables:
    <ul>
      <li><strong>HADOOP_HOME</strong> Environment variables refers to where Hadoop lives</li>
      <li><strong>MAHOUT_HOME</strong> Environment variables refers to where Mahout lives</li>
    </ul>
  </li>
</ul>

<p><a name="TwentyNewsgroups-Instructionsforrunningtheexample"></a></p>
<h3 id="instructions-for-running-the-example">Instructions for running the example</h3>

<ol>
  <li>
    <p>If running Hadoop in cluster mode, start the hadoop daemons by executing the following commands:</p>

    <pre><code>     $ cd $HADOOP_HOME/bin
     $ ./start-all.sh
</code></pre>

    <p>Otherwise:</p>

    <pre><code>     $ export MAHOUT_LOCAL=true
</code></pre>
  </li>
  <li>
    <p>In the trunk directory of Mahout, compile and install Mahout:</p>

    <pre><code>     $ cd $MAHOUT_HOME
     $ mvn -DskipTests clean install
</code></pre>
  </li>
  <li>
    <p>Run the <a href="https://github.com/apache/mahout/blob/master/examples/bin/classify-20newsgroups.sh">20 newsgroups example script</a> by executing:</p>

    <pre><code>     $ ./examples/bin/classify-20newsgroups.sh
</code></pre>
  </li>
  <li>
    <p>You will be prompted to select a classification method algorithm:</p>

    <pre><code>     1. Complement Naive Bayes
     2. Naive Bayes
     3. Stochastic Gradient Descent
</code></pre>
  </li>
</ol>

<p>Select 1 and the the script will perform the following:</p>

<ol>
  <li>Create a working directory for the dataset and all input/output.</li>
  <li>Download and extract the <em>20news-bydate.tar.gz</em> from the <a href="http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz">20 newsgroups dataset</a> to the working directory.</li>
  <li>Convert the full 20 newsgroups dataset into a &lt; Text, Text &gt; SequenceFile.</li>
  <li>Convert and preprocesses the dataset into a &lt; Text, VectorWritable &gt; SequenceFile containing term frequencies for each document.</li>
  <li>Split the preprocessed dataset into training and testing sets.</li>
  <li>Train the classifier.</li>
  <li>Test the classifier.</li>
</ol>

<p>Output should look something like:</p>

<pre><code>=======================================================
Confusion Matrix
-------------------------------------------------------
 a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t &lt;--Classified as
381 0  0  0  0  9  1  0  0  0  1  0  0  2  0  1  0  0  3  0 |398 a=rec.motorcycles
 1 284 0  0  0  0  1  0  6  3  11 0  66 3  0  6  0  4  9  0 |395 b=comp.windows.x
 2  0 339 2  0  3  5  1  0  0  0  0  1  1  12 1  7  0  2  0 |376 c=talk.politics.mideast
 4  0  1 327 0  2  2  0  0  2  1  1  0  5  1  4  12 0  2  0 |364 d=talk.politics.guns
 7  0  4  32 27 7  7  2  0  12 0  0  6  0 100 9  7  31 0  0 |251 e=talk.religion.misc
 10 0  0  0  0 359 2  2  0  0  3  0  1  6  0  1  0  0  11 0 |396 f=rec.autos
 0  0  0  0  0  1 383 9  1  0  0  0  0  0  0  0  0  3  0  0 |397 g=rec.sport.baseball
 1  0  0  0  0  0  9 382 0  0  0  0  1  1  1  0  2  0  2  0 |399 h=rec.sport.hockey
 2  0  0  0  0  4  3  0 330 4  4  0  5  12 0  0  2  0  12 7 |385 i=comp.sys.mac.hardware
 0  3  0  0  0  0  1  0  0 368 0  0  10 4  1  3  2  0  2  0 |394 j=sci.space
 0  0  0  0  0  3  1  0  27 2 291 0  11 25 0  0  1  0  13 18|392 k=comp.sys.ibm.pc.hardware
 8  0  1 109 0  6  11 4  1  18 0  98 1  3  11 10 27 1  1  0 |310 l=talk.politics.misc
 0  11 0  0  0  3  6  0  10 6  11 0 299 13 0  2  13 0  7  8 |389 m=comp.graphics
 6  0  1  0  0  4  2  0  5  2  12 0  8 321 0  4  14 0  8  6 |393 n=sci.electronics
 2  0  0  0  0  0  4  1  0  3  1  0  3  1 372 6  0  2  1  2 |398 o=soc.religion.christian
 4  0  0  1  0  2  3  3  0  4  2  0  7  12 6 342 1  0  9  0 |396 p=sci.med
 0  1  0  1  0  1  4  0  3  0  1  0  8  4  0  2 369 0  1  1 |396 q=sci.crypt
 10 0  4  10 1  5  6  2  2  6  2  0  2  1 86 15 14 152 0  1 |319 r=alt.atheism
 4  0  0  0  0  9  1  1  8  1  12 0  3  0  2  0  0  0 341 2 |390 s=misc.forsale
 8  5  0  0  0  1  6  0  8  5  50 0  40 2  1  0  9  0  3 256|394 t=comp.os.ms-windows.misc
=======================================================
Statistics
-------------------------------------------------------
Kappa                                       0.8808
Accuracy                                   90.8596%
Reliability                                86.3632%
Reliability (standard deviation)            0.2131
</code></pre>

<p><a name="TwentyNewsgroups-ComplementaryNaiveBayes"></a></p>
<h2 id="end-to-end-commands-to-build-a-cbayes-model-for-20-newsgroups">End to end commands to build a CBayes model for 20 newsgroups</h2>
<p>The <a href="https://github.com/apache/mahout/blob/master/examples/bin/classify-20newsgroups.sh">20 newsgroups example script</a> issues the following commands as outlined above. We can build a CBayes classifier from the command line by following the process in the script:</p>

<p><em>Be sure that <strong>MAHOUT_HOME</strong>/bin and <strong>HADOOP_HOME</strong>/bin are in your <strong>$PATH</strong></em></p>

<ol>
  <li>
    <p>Create a working directory for the dataset and all input/output.</p>

    <pre><code>     $ export WORK_DIR=/tmp/mahout-work-${USER}
     $ mkdir -p ${WORK_DIR}
</code></pre>
  </li>
  <li>
    <p>Download and extract the <em>20news-bydate.tar.gz</em> from the <a href="http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz">20newsgroups dataset</a> to the working directory.</p>

    <pre><code>     $ curl http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz 
         -o ${WORK_DIR}/20news-bydate.tar.gz
     $ mkdir -p ${WORK_DIR}/20news-bydate
     $ cd ${WORK_DIR}/20news-bydate &amp;&amp; tar xzf ../20news-bydate.tar.gz &amp;&amp; cd .. &amp;&amp; cd ..
     $ mkdir ${WORK_DIR}/20news-all
     $ cp -R ${WORK_DIR}/20news-bydate/*/* ${WORK_DIR}/20news-all   * If you're running on a Hadoop cluster:
 
     $ hadoop dfs -put ${WORK_DIR}/20news-all ${WORK_DIR}/20news-all
</code></pre>
  </li>
  <li>
    <p>Convert the full 20 newsgroups dataset into a &lt; Text, Text &gt; SequenceFile.</p>

    <pre><code>     $ mahout seqdirectory 
         -i ${WORK_DIR}/20news-all 
         -o ${WORK_DIR}/20news-seq 
         -ow
</code></pre>
  </li>
  <li>
    <p>Convert and preprocesses the dataset into  a &lt; Text, VectorWritable &gt; SequenceFile containing term frequencies for each document.</p>

    <pre><code>     $ mahout seq2sparse 
         -i ${WORK_DIR}/20news-seq 
         -o ${WORK_DIR}/20news-vectors
         -lnorm 
         -nv 
         -wt tfidf If we wanted to use different parsing methods or transformations on the term frequency vectors we could supply different options here e.g.: -ng 2 for bigrams or -n 2 for L2 length normalization.  See the [Creating vectors from text](http://mahout.apache.org/users/basics/creating-vectors-from-text.html) page for a list of all seq2sparse options.   
</code></pre>
  </li>
  <li>
    <p>Split the preprocessed dataset into training and testing sets.</p>

    <pre><code>     $ mahout split 
         -i ${WORK_DIR}/20news-vectors/tfidf-vectors 
         --trainingOutput ${WORK_DIR}/20news-train-vectors 
         --testOutput ${WORK_DIR}/20news-test-vectors  
         --randomSelectionPct 40 
         --overwrite --sequenceFiles -xm sequential
</code></pre>
  </li>
  <li>
    <p>Train the classifier.</p>

    <pre><code>     $ mahout trainnb 
         -i ${WORK_DIR}/20news-train-vectors
         -el  
         -o ${WORK_DIR}/model 
         -li ${WORK_DIR}/labelindex 
         -ow 
         -c
</code></pre>
  </li>
  <li>
    <p>Test the classifier.</p>

    <pre><code>     $ mahout testnb 
         -i ${WORK_DIR}/20news-test-vectors
         -m ${WORK_DIR}/model 
         -l ${WORK_DIR}/labelindex 
         -ow 
         -o ${WORK_DIR}/20news-testing 
         -c
</code></pre>
  </li>
</ol>


   </div>
  </div>     
</div> 
  <footer class="footer" align="center">
    <div class="container">
      <p>
        Copyright &copy; 2014-2016 The Apache Software Foundation, Licensed under
        the <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache License, Version 2.0</a>.
        <br />
		  Apache Mahout, Mahout, Apache, the Apache feather logo, and the elephant rider logo are either registered trademarks or trademarks of <a href="http://www.apache.org/foundation/marks/">The Apache Software Foundation</a> in the United States and other countries.
      </p>
    </div>
  </footer>
  
  <script src="/assets/themes/mahout-retro/js/jquery-1.9.1.min.js"></script>
  <script src="/assets/themes/mahout-retro/js/bootstrap.min.js"></script>
  <script>
    (function() {
      var cx = '012254517474945470291:vhsfv7eokdc';
      var gcse = document.createElement('script');
      gcse.type = 'text/javascript';
      gcse.async = true;
      gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
          '//www.google.com/cse/cse.js?cx=' + cx;
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(gcse, s);
    })();
  </script>
</body>
</html>

