

<!DOCTYPE html>
<!--

    Licensed to the Apache Software Foundation (ASF) under one or more
    contributor license agreements.  See the NOTICE file distributed with
    this work for additional information regarding copyright ownership.
    The ASF licenses this file to You under the Apache License, Version 2.0
    (the "License"); you may not use this file except in compliance with
    the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
-->

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Apache Mahout: Scalable machine learning and data mining</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="Distribution" content="Global">
  <meta name="Robots" content="index,follow">
  <meta name="keywords" content="apache, apache hadoop, apache lucene,
        business data mining, cluster analysis,
        collaborative filtering, data extraction, data filtering, data framework, data integration,
        data matching, data mining, data mining algorithms, data mining analysis, data mining data,
        data mining introduction, data mining software,
        data mining techniques, data representation, data set, datamining,
        feature extraction, fuzzy k means, genetic algorithm, hadoop,
        hierarchical clustering, high dimensional, introduction to data mining, kmeans,
        knowledge discovery, learning approach, learning approaches, learning methods,
        learning techniques, lucene, machine learning, machine translation, mahout apache,
        mahout taste, map reduce hadoop, mining data, mining methods, naive bayes,
        natural language processing,
        supervised, text mining, time series data, unsupervised, web data mining">
  <link rel="shortcut icon" type="image/x-icon" href="https://mahout.apache.org/images/favicon.ico">
  <!--<script type="text/javascript" src="/js/prototype.js"></script>-->
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/prototype/1.7.2.0/prototype.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/effects.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/search.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/slides.js"></script>

  <link href="/assets/themes/mahout-retro/css/bootstrap.min.css" rel="stylesheet" media="screen">
  <link href="/assets/themes/mahout-retro/css/bootstrap-responsive.css" rel="stylesheet">
  <link rel="stylesheet" href="/assets/themes/mahout-retro/css/global.css" type="text/css">

  <!-- mathJax stuff -- use `\(...\)` for inline style math in markdown -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
  </script>
  <script type="text/javascript">
    var mathjax = document.createElement('script'); 
    mathjax.type = 'text/javascript'; 
    mathjax.async = true;

    mathjax.src = ('https:' == document.location.protocol) ?
        'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML' : 
        'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
	
	  var s = document.getElementsByTagName('script')[0]; 
    s.parentNode.insertBefore(mathjax, s);
  </script>
</head>

<body id="home" data-twttr-rendered="true">
  <div id="wrap">
   <div id="header">
    <div id="logo"><a href="/"><img src="/assets/img/mahout-logo-brudman.png" alt="Logos for Mahout and Apache Software Foundation" /></a></div>
  <div id="search">
    <form id="search-form" action="http://www.google.com/search" method="get" class="navbar-search pull-right">    
      <input value="http://mahout.apache.org" name="sitesearch" type="hidden">
      <input class="search-query" name="q" id="query" type="text">
      <input id="submission" type="image" src="/assets/img/mahout-lupe.png" alt="Search" />
    </form>
  </div>
 
    <div class="navbar navbar-inverse" style="position:absolute;top:133px;padding-right:0px;padding-left:0px;">
      <div class="navbar-inner" style="border: none; background: #999; border: none; border-radius: 0px;">
        <div class="container">
          <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!-- <a class="brand" href="#">Apache Community Development Project</a> -->
            <!--<div class="nav-collapse collapse">-->
<div class="collapse navbar-collapse" id="main-navbar">
    <ul class="nav navbar-nav">
        <!-- <li><a href="/">Home</a></li> -->
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">General<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/general/downloads.html">Downloads</a>
                <li><a href="/general/who-we-are.html">Who we are</a>
                <li><a href="/general/mailing-lists,-irc-and-archives.html">Mailing Lists</a>
                <li><a href="/general/release-notes.html">Release Notes</a>
                <li><a href="/general/books-tutorials-and-talks.html">Books, Tutorials, Talks</a></li>
                <li><a href="/general/powered-by-mahout.html">Powered By Mahout</a>
                <li><a href="/general/professional-support.html">Professional Support</a>
                <li class="divider"></li>
                <li class="nav-header">Resources</li>
                <li><a href="/general/reference-reading.html">Reference Reading</a>
                <li><a href="/general/faq.html">FAQ</a>
                <li class="divider"></li>
                <li class="nav-header">Legal</li>
                <li><a href="http://www.apache.org/licenses/">License</a></li>
                <li><a href="http://www.apache.org/security/">Security</a></li>
                <li><a href="/general/privacy-policy.html">Privacy Policy</a>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Developers<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/developers/developer-resources.html">Developer resources</a></li>
                <li><a href="/developers/version-control.html">Version control</a></li>
                <li><a href="/developers/buildingmahout.html">Build from source</a></li>
                <li><a href="/developers/issue-tracker.html">Issue tracker</a></li>
                <li><a href="https://builds.apache.org/job/Mahout-Quality/" target="_blank">Code quality reports</a></li>
                <li class="divider"></li>
                <li class="nav-header">Contributions</li>
                <li><a href="/developers/how-to-contribute.html">How to contribute</a></li>
                <li><a href="/developers/how-to-become-a-committer.html">How to become a committer</a></li>
                <li><a href="/developers/gsoc.html">GSoC</a></li>
                <li class="divider"></li>
                <li class="nav-header">For committers</li>
                <li><a href="/developers/how-to-update-the-website.html">How to update the website</a></li>
                <li><a href="/developers/patch-check-list.html">Patch check list</a></li>
                <li><a href="/developers/github.html">Handling Github PRs</a></li>
                <li><a href="/developers/how-to-release.html">How to release</a></li>
                <li><a href="/developers/thirdparty-dependencies.html">Third party dependencies</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Mahout-Samsara<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/sparkbindings/home.html">Scala &amp; Spark Bindings Overview</a></li>
                <li><a href="/users/sparkbindings/faq.html">FAQ</a></li>
                <li><a href="/users/flinkbindings/playing-with-samsara-flink.html">Flink Bindings Overview</a></li>
                <li class="nav-header">Engines</li>
                <li><a href="/users/sparkbindings/home.html">Spark</a></li>
                <li><a href="/users/environment/h2o-internals.html">H2O</a></li>
                <li><a href="/users/flinkbindings/flink-internals.html">Flink</a></li>
                <li class="nav-header">References</li>
                <li><a href="/users/environment/in-core-reference.html">In-Core Algebraic DSL Reference</a></li>
                <li><a href="/users/environment/out-of-core-reference.html">Distributed Algebraic DSL Reference</a></li>
                <li class="nav-header">Tutorials</li>
                <li><a href="/users/sparkbindings/play-with-shell.html">Playing with Mahout's Spark Shell</a></li>
                <li><a href="/users/environment/how-to-build-an-app.html">How to build an app</a></li>
                <li><a href="/users/environment/classify-a-doc-from-the-shell.html">Building a text classifier in Mahout's Spark Shell</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Algorithms<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/basics/algorithms.html">List of algorithms</a>
                <li class="nav-header">Distributed Matrix Decomposition</li>
                <li><a href="/users/algorithms/d-qr.html">Cholesky QR</a></li>
                <li><a href="/users/algorithms/d-ssvd.html">SSVD</a></li>
                <li><a href="/users/algorithms/d-als.html">Distributed ALS</a></li>
                <li><a href="/users/algorithms/d-spca.html">SPCA</a></li>
                <li class="nav-header">Recommendations</li>
                <li><a href="/users/algorithms/recommender-overview.html">Recommender Overview</a></li>
                <li><a href="/users/algorithms/intro-cooccurrence-spark.html">Intro to cooccurrence-based<br/> recommendations with Spark</a></li>
                <li class="nav-header">Classification</li>
                <li><a href="/users/algorithms/spark-naive-bayes.html">Spark Naive Bayes</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">MapReduce Basics<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/basics/algorithms.html">List of algorithms</a>
                <li><a href="/users/basics/quickstart.html">Overview</a>
                <li class="divider"></li>
                <li class="nav-header">Working with text</li>
                <li><a href="/users/basics/creating-vectors-from-text.html">Creating vectors from text</a>
                <li><a href="/users/basics/collocations.html">Collocations</a>
                <li class="divider"></li>
                <li class="nav-header">Dimensionality reduction</li>
                <li><a href="/users/dim-reduction/dimensional-reduction.html">Singular Value Decomposition</a></li>
                <li><a href="/users/dim-reduction/ssvd.html">Stochastic SVD</a></li>
                <li class="divider"></li>
                <li class="nav-header">Topic Models</li>
                <li><a href="/users/clustering/latent-dirichlet-allocation.html">Latent Dirichlet Allocation</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Mahout MapReduce<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li class="nav-header">Classification</li>
                <li><a href="/users/classification/bayesian.html">Naive Bayes</a></li>
                <li><a href="/users/classification/hidden-markov-models.html">Hidden Markov Models</a></li>
                <li><a href="/users/classification/logistic-regression.html">Logistic Regression (Single Machine)</a></li>
                <li><a href="/users/classification/partial-implementation.html">Random Forest</a></li>
                <li class="nav-header">Classification Examples</li>
                <li><a href="/users/classification/breiman-example.html">Breiman example</a></li>
                <li><a href="/users/classification/twenty-newsgroups.html">20 newsgroups example</a></li>
                <li><a href="/users/classification/bankmarketing-example.html">SGD classifier bank marketing</a></li>
                <li><a href="/users/classification/wikipedia-classifier-example.html">Wikipedia XML parser and classifier</a></li>
                <li class="nav-header">Clustering</li>
                <li><a href="/users/clustering/k-means-clustering.html">k-Means</a></li>
                <li><a href="/users/clustering/canopy-clustering.html">Canopy</a></li>
                <li><a href="/users/clustering/fuzzy-k-means.html">Fuzzy k-Means</a></li>
                <li><a href="/users/clustering/streaming-k-means.html">Streaming KMeans</a></li>
                <li><a href="/users/clustering/spectral-clustering.html">Spectral Clustering</a></li>
                <li class="nav-header">Clustering Commandline usage</li>
                <li><a href="/users/clustering/k-means-commandline.html">Options for k-Means</a></li>
                <li><a href="/users/clustering/canopy-commandline.html">Options for Canopy</a></li>
                <li><a href="/users/clustering/fuzzy-k-means-commandline.html">Options for Fuzzy k-Means</a></li>
                <li class="nav-header">Clustering Examples</li>
                <li><a href="/users/clustering/clustering-of-synthetic-control-data.html">Synthetic data</a></li>
                <li class="nav-header">Cluster Post processing</li>
                <li><a href="/users/clustering/cluster-dumper.html">Cluster Dumper tool</a></li>
                <li><a href="/users/clustering/visualizing-sample-clusters.html">Cluster visualisation</a></li>
                <li class="nav-header">Recommendations</li>
                <li><a href="/users/recommender/recommender-first-timer-faq.html">First Timer FAQ</a></li>
                <li><a href="/users/recommender/userbased-5-minutes.html">A user-based recommender <br/>in 5 minutes</a></li>
                <li><a href="/users/recommender/matrix-factorization.html">Matrix factorization-based<br/> recommenders</a></li>
                <li><a href="/users/recommender/recommender-documentation.html">Overview</a></li>
                <li><a href="/users/recommender/intro-itembased-hadoop.html">Intro to item-based recommendations<br/> with Hadoop</a></li>
                <li><a href="/users/recommender/intro-als-hadoop.html">Intro to ALS recommendations<br/> with Hadoop</a></li>
            </ul>
        </li>
        <!--  <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Recommendations<b class="caret"></b></a>
          <ul class="dropdown-menu">

          </ul> -->
        </li>
    </ul>
</div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

</div>

 <div id="sidebar">
  <div id="sidebar-wrap">
    <h2>Twitter</h2>
	<ul class="sidemenu">
		<li>
<a class="twitter-timeline" href="https://twitter.com/ApacheMahout" data-widget-id="422861673444028416">Tweets by @ApacheMahout</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</li>
	</ul>
    <h2>Apache Software Foundation</h2>
    <ul class="sidemenu">
      <li><a href="http://www.apache.org/foundation/how-it-works.html">How the ASF works</a></li>
      <li><a href="http://www.apache.org/foundation/getinvolved.html">Get Involved</a></li>
      <li><a href="http://www.apache.org/dev/">Developer Resources</a></li>
      <li><a href="http://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
      <li><a href="http://www.apache.org/foundation/thanks.html">Thanks</a></li>
    </ul>
    <h2>Related Projects</h2>
    <ul class="sidemenu">
      <li><a href="http://lucene.apache.org/">Apache Lucene</a></li>
      <li><a href="http://hadoop.apache.org/">Apache Hadoop</a></li>
      <li><a href="http://bigtop.apache.org/">Apache Bigtop</a></li>
      <li><a href="http://spark.apache.org/">Apache Spark</a></li>
	  <li><a href="http://flink.apache.org/">Apache Flink</a></li>
    </ul>
  </div>
</div>

  <div id="content-wrap" class="clearfix">
   <div id="main">

    <p><a name="RandomForests-HowtogrowaDecisionTree"></a></p>
<h3 id="how-to-grow-a-decision-tree">How to grow a Decision Tree</h3>

<p>source : [3](3.html)</p>

<p>LearnUnprunedTree(<em>X</em>,<em>Y</em>)</p>

<p>Input: <em>X</em> a matrix of <em>R</em> rows and <em>M</em> columns where <em>X{</em>}{<em>}{~}ij{~}</em> =
the value of the <em>j</em>‘th attribute in the <em>i</em>‘th input datapoint. Each
column consists of either all real values or all categorical values.
Input: <em>Y</em> a vector of <em>R</em> elements, where <em>Y{</em>}{<em>}{~}i{~}</em> = the output
class of the <em>i</em>‘th datapoint. The <em>Y{</em>}{<em>}{~}i{~}</em> values are categorical.
Output: An Unpruned decision tree</p>

<p>If all records in <em>X</em> have identical values in all their attributes (this
includes the case where <em>R&lt;2</em>), return a Leaf Node predicting the majority
output, breaking ties randomly. This case also includes
If all values in <em>Y</em> are the same, return a Leaf Node predicting this value
as the output
Else
    select <em>m</em> variables at random out of the <em>M</em> variables
    For <em>j</em> = 1 .. <em>m</em>
        If <em>j</em>‘th attribute is
categorical
<em>           
IG{</em>}{<em>}{~}j{~}</em> = IG(<em>Y</em>|<em>X{</em>}{<em>}{~}j{~}</em>) (see Information
Gain)            
        Else (<em>j</em>‘th attribute is
real-valued)
<em>           
IG{</em>}{<em>}{~}j{~}</em> = IG<em>(</em>Y<em>|</em>X{<em>}{</em>}{~}j{~}<em>) (see Information Gain)
    Let *j*</em> = argmax{~}j~ <em>IG{</em>}{<em>}{~}j{~}</em> (this is the
splitting attribute we’ll use)
    If <em>j*</em> is categorical then
        For each value <em>v</em> of the <em>j</em>‘th
attribute
            Let
<em>X{</em>}{<em>}{^}v{^}</em> = subset of rows of <em>X</em> in which <em>X{</em>}{<em>}{~}ij{~}</em> = <em>v</em>.
Let <em>Y{</em>}{<em>}{^}v{^}</em> = corresponding subset of <em>Y</em>
            Let <em>Child{</em>}{<em>}{^}v{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}v{^}</em>,<em>Y{</em>}{<em>}{^}v{^}</em>)
        Return a decision tree node,
splitting on <em>j</em>‘th attribute. The number of children equals the number of
values of the <em>j</em>‘th attribute, and the <em>v</em>‘th child is
<em>Child{</em>}{<em>}{^}v{^}</em>
    Else <em>j*</em> is real-valued and let <em>t</em> be the best split
threshold
        Let <em>X{</em>}{<em>}{^}LO{^}</em> = subset
of rows of <em>X</em> in which <em>X{</em>}{<em>}{~}ij{~}</em> <em>&lt;= t</em>. Let <em>Y{</em>}{<em>}{^}LO{^}</em> =
corresponding subset of <em>Y</em>
        Let <em>Child{</em>}{<em>}{^}LO{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}LO{^}</em>,<em>Y{</em>}{<em>}{^}LO{^}</em>)
        Let <em>X{</em>}{<em>}{^}HI{^}</em> = subset of rows of <em>X</em>
in which <em>X{</em>}{<em>}{~}ij{~}</em> <em>&gt; t</em>. Let <em>Y{</em>}{<em>}{^}HI{^}</em> = corresponding
subset of <em>Y</em>
        Let <em>Child{</em>}{<em>}{^}HI{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}HI{^}</em>,<em>Y{</em>}{<em>}{^}HI{^}</em>)
        Return a decision tree node, splitting on
<em>j</em>‘th attribute. It has two children corresponding to whether the <em>j</em>‘th
attribute is above or below the given threshold.</p>

<p><em>Note</em>: There are alternatives to Information Gain for splitting nodes
 </p>

<p><a name="RandomForests-Informationgain"></a></p>
<h3 id="information-gain">Information gain</h3>

<p>source : [3](3.html)</p>
<ol>
  <li>h4. nominal attributes</li>
</ol>

<p>suppose X can have one of m values V{~}1~,V{~}2~,…,V{~}m~
P(X=V{~}1~)=p{~}1~, P(X=V{~}2~)=p{~}2~,…,P(X=V{~}m~)=p{~}m~
 
H(X)= -sum{~}j=1{~}{^}m^ p{~}j~ log{~}2~ p{~}j~ (The entropy of X)
H(Y|X=v) = the entropy of Y among only those records in which X has value
v
H(Y|X) = sum{~}j~ p{~}j~ H(Y|X=v{~}j~)
IG(Y|X) = H(Y) - H(Y|X)</p>
<ol>
  <li>h4. real-valued attributes</li>
</ol>

<p>suppose X is real valued
define IG(Y|X:t) as H(Y) - H(Y|X:t)
define H(Y|X:t) = H(Y|X&lt;t) P(X&lt;t) + H(Y|X&gt;=t) P(X&gt;=t)
define IG*(Y|X) = max{~}t~ IG(Y|X:t)</p>

<p><a name="RandomForests-HowtogrowaRandomForest"></a></p>
<h3 id="how-to-grow-a-random-forest">How to grow a Random Forest</h3>

<p>source : [1](1.html)</p>

<p>Each tree is grown as follows:</p>
<ol>
  <li>if the number of cases in the training set is <em>N</em>, sample <em>N</em> cases at
random -but with replacement, from the original data. This sample will be
the training set for the growing tree.</li>
  <li>if there are <em>M</em> input variables, a number <em>m « M</em> is specified such
that at each node, <em>m</em> variables are selected at random out of the <em>M</em> and
the best split on these <em>m</em> is used to split the node. The value of <em>m</em> is
held constant during the forest growing.</li>
  <li>each tree is grown to its large extent possible. There is no pruning.</li>
</ol>

<p><a name="RandomForests-RandomForestparameters"></a></p>
<h3 id="random-forest-parameters">Random Forest parameters</h3>

<p>source : [2](2.html)
Random Forests are easy to use, the only 2 parameters a user of the
technique has to determine are the number of trees to be used and the
number of variables (<em>m</em>) to be randomly selected from the available set of
variables.
Breinman’s recommendations are to pick a large number of trees, as well as
the square root of the number of variables for <em>m</em>.
 </p>

<p><a name="RandomForests-Howtopredictthelabelofacase"></a></p>
<h3 id="how-to-predict-the-label-of-a-case">How to predict the label of a case</h3>

<p>Classify(<em>node</em>,<em>V</em>)
    Input: <em>node</em> from the decision tree, if <em>node.attribute
= j</em> then the split is done on the <em>j</em>‘th attribute</p>

<p>    Input: <em>V</em> a vector of <em>M</em> columns where
<em>V{</em>}{<em>}{~}j{~}</em> = the value of the <em>j</em>‘th attribute.
    Output: label of <em>V</em></p>

<p>    If <em>node</em> is a Leaf then
            Return the value predicted
by <em>node</em></p>

<p>    Else
            Let <em>j =
node.attribute</em>
            If <em>j</em> is
categorical then
      
            
Let <em>v</em> = <em>V{</em>}{<em>}{~}j{~}</em>
      
            
Let <em>child{</em>}{<em>}{^}v{^}</em> = child node corresponding to the attribute’s
value <em>v</em>
              
     Return Classify(<em>child{</em>}{<em>}{^}v{^}</em>,<em>V</em>)</p>

<p>            Else <em>j</em> is
real-valued
      
            
Let <em>t = node.threshold</em> (split threshold)
              
     If Vj &lt; t then
                  
         Let <em>child{</em>}{<em>}{^}LO{^}</em> = child
node corresponding to (<em>&lt;t</em>)
                  
         Return
Classify(<em>child{</em>}{<em>}{^}LO{^}</em>,<em>V</em>)
      
            
Else
                  
         Let <em>child{</em>}{<em>}{^}HI{^}</em> =
child node corresponding to (<em>&gt;=t</em>)
               
            Return
Classify(<em>child{</em>}{<em>}{^}HI{^}</em>,<em>V</em>)
 </p>

<p><a name="RandomForests-Theoutofbag(oob)errorestimation"></a></p>
<h3 id="the-out-of-bag-oob-error-estimation">The out of bag (oob) error estimation</h3>

<p>source : [1](1.html)</p>

<p>in random forests, there is no need for cross-validation or a separate test
set to get an unbiased estimate of the test set error. It is estimated
internally, during the run, as follows:</p>
<ul>
  <li>each tree is constructed using a different bootstrap sample from the
original data. About one-third of the cases left of the bootstrap sample
and not used in the construction of the <em>kth</em> tree.</li>
  <li>put each case left out in the construction of the <em>kth</em> tree down the
<em>kth{</em>}tree to get a classification. In this way, a test set classification
is obtained for each case in about one-thrid of the trees. At the end of
the run, take <em>j</em> to be the class that got most of the the votes every time
case <em>n</em> was <em>oob</em>. The proportion of times that <em>j</em> is not equal to the
true class of <em>n</em> averaged over all cases is the <em>oob error estimate</em>. This
has proven to be unbiased in many tests.</li>
</ul>

<p><a name="RandomForests-OtherRFuses"></a></p>
<h3 id="other-rf-uses">Other RF uses</h3>

<p>source : [1](1.html)</p>
<ul>
  <li>variable importance</li>
  <li>gini importance</li>
  <li>proximities</li>
  <li>scaling</li>
  <li>prototypes</li>
  <li>missing values replacement for the training set</li>
  <li>missing values replacement for the test set</li>
  <li>detecting mislabeled cases</li>
  <li>detecting outliers</li>
  <li>detecting novelties</li>
  <li>unsupervised learning</li>
  <li>balancing prediction error
Please refer to [1](1.html)
 for a detailed description</li>
</ul>

<p><a name="RandomForests-References"></a></p>
<h3 id="references">References</h3>

<p>[1](1.html)
  Random Forests - Classification Description
        <a href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</a>
[2](2.html)
  B. Larivi�re &amp; D. Van Den Poel, 2004. “Predicting Customer Retention
and Profitability by Using Random Forests and Regression Forests
Techniques,”
        Working Papers of Faculty of
Economics and Business Administration, Ghent University, Belgium 04/282,
Ghent University,
        Faculty of Economics and
Business Administration.
        Available online : <a href="http://ideas.repec.org/p/rug/rugwps/04-282.html">http://ideas.repec.org/p/rug/rugwps/04-282.html</a>
[3](3.html)
  Decision Trees - Andrew W. Moore[4]
        http://www.cs.cmu.edu/~awm/tutorials[1](1.html)
[4](4.html)
  Information Gain - Andrew W. Moore
        <a href="http://www.cs.cmu.edu/~awm/tutorials">http://www.cs.cmu.edu/~awm/tutorials</a></p>

   </div>
  </div>     
</div> 
  <footer class="footer" align="center">
    <div class="container">
      <p>
        Copyright &copy; 2014-2016 The Apache Software Foundation, Licensed under
        the <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache License, Version 2.0</a>.
        <br />
		  Apache Mahout, Mahout, Apache, the Apache feather logo, and the elephant rider logo are either registered trademarks or trademarks of <a href="http://www.apache.org/foundation/marks/">The Apache Software Foundation</a> in the United States and other countries.
      </p>
    </div>
  </footer>
  
  <script src="/assets/themes/mahout-retro/js/jquery-1.9.1.min.js"></script>
  <script src="/assets/themes/mahout-retro/js/bootstrap.min.js"></script>
  <script>
    (function() {
      var cx = '012254517474945470291:vhsfv7eokdc';
      var gcse = document.createElement('script');
      gcse.type = 'text/javascript';
      gcse.async = true;
      gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
          '//www.google.com/cse/cse.js?cx=' + cx;
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(gcse, s);
    })();
  </script>
</body>
</html>

